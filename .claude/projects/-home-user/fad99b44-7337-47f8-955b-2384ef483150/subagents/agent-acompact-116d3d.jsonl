{"parentUuid":"de70c99b-a42a-4a4b-8d4c-2fce6c05d5aa","isSidechain":true,"userType":"external","cwd":"/home/user/sentinelpi","sessionId":"fad99b44-7337-47f8-955b-2384ef483150","version":"2.1.31","gitBranch":"HEAD","agentId":"acompact-116d3d","slug":"reactive-humming-rainbow","message":{"model":"claude-opus-4-5-20251101","id":"msg_019GsCvFc1HCuUSAbELUpDzc","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Biu2XqEs9SoVoZBj5AoRHh","name":"Edit","input":{"replace_all":false,"file_path":"/home/user/sentinelpi/src/dashboard/app.py","old_string":"    with tabs[1]:\n        with st.form(\"settings_collection\"):\n            col1, col2 = st.columns(2)\n            coll = raw.get(\"collection\", {})\n            with col1:\n                coll_interval = st.number_input(\"Intervalle par defaut (min)\", value=coll.get(\"default_interval_minutes\", 60), min_value=5)\n                coll_concurrent = st.number_input(\"Collecteurs simultanes\", value=coll.get(\"max_concurrent_collectors\", 3), min_value=1, max_value=10)\n                coll_timeout = st.number_input(\"Timeout collecteur (s)\", value=coll.get(\"collector_timeout\", 120), min_value=10)\n            with col2:\n                coll_max_items = st.number_input(\"Items max par source\", value=coll.get(\"max_items_per_source\", 100), min_value=10)\n                coll_dedup = st.number_input(\"Fenetre dedup (jours)\", value=coll.get(\"dedup_window_days\", 30), min_value=1)\n\n            st.divider()\n            http = raw.get(\"http\", {})\n            col1, col2 = st.columns(2)\n            with col1:\n                http_timeout = st.number_input(\"HTTP timeout (s)\", value=http.get(\"timeout\", 30), min_value=5)\n                http_retries = st.number_input(\"HTTP retries\", value=http.get(\"max_retries\", 3), min_value=0)\n            with col2:\n                http_rate = st.number_input(\"Rate limit (req/s)\", value=http.get(\"rate_limit\", 2), min_value=1)\n                http_ua = st.text_input(\"User-Agent\", value=http.get(\"user_agent\", \"\"))\n\n            st.divider()\n            st.subheader(\"Scheduler\")\n            sched = raw.get(\"scheduler\", {})\n            col1, col2 = st.columns(2)\n            with col1:\n                sched_enabled = st.checkbox(\"Scheduler actif\", value=sched.get(\"enabled\", True))\n                daily_time = st.text_input(\"Rapport quotidien (HH:MM)\", value=sched.get(\"daily_report_time\", \"08:00\"))\n            with col2:\n                weekly_day = st.number_input(\"Jour rapport hebdo (0=lun)\", value=sched.get(\"weekly_report_day\", 0), min_value=0, max_value=6)\n                weekly_time = st.text_input(\"Heure rapport hebdo\", value=sched.get(\"weekly_report_time\", \"09:00\"))\n\n            if st.form_submit_button(\"ðŸ’¾ Sauvegarder Collecte\", use_container_width=True):\n                new_config = dict(raw)\n                new_config[\"collection\"] = {\n                    \"default_interval_minutes\": coll_interval,\n                    \"max_concurrent_collectors\": coll_concurrent,\n                    \"max_items_per_source\": coll_max_items,\n                    \"dedup_window_days\": coll_dedup,\n                    \"collector_timeout\": coll_timeout,\n                }\n                new_config[\"http\"] = {\n                    \"timeout\": http_timeout, \"max_retries\": http_retries,\n                    \"retry_delay\": raw.get(\"http\", {}).get(\"retry_delay\", 5),\n                    \"user_agent\": http_ua, \"rate_limit\": http_rate,\n                    \"cache\": raw.get(\"http\", {}).get(\"cache\", {}),\n                }\n                new_config[\"scheduler\"] = {\n                    \"enabled\": sched_enabled,\n                    \"check_interval_seconds\": sched.get(\"check_interval_seconds\", 60),\n                    \"daily_report_time\": daily_time,\n                    \"weekly_report_day\": weekly_day,\n                    \"weekly_report_time\": weekly_time,\n                }\n                try:\n                    _save_settings_yaml(new_config)\n                    st.success(\"Parametres de collecte sauvegardes !\")\n                except Exception as e:\n                    st.error(f\"Erreur: {e}\")","new_string":"    with tabs[1]:\n        import json as _json_coll\n\n        # Default browser-like headers\n        DEFAULT_UA = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n        DEFAULT_ACCEPT = \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\"\n        DEFAULT_ACCEPT_LANG = \"fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7\"\n\n        with st.form(\"settings_collection\"):\n            col1, col2 = st.columns(2)\n            coll = raw.get(\"collection\", {})\n            with col1:\n                coll_interval = st.number_input(\"Intervalle par defaut (min)\", value=coll.get(\"default_interval_minutes\", 60), min_value=5)\n                coll_concurrent = st.number_input(\"Collecteurs simultanes\", value=coll.get(\"max_concurrent_collectors\", 3), min_value=1, max_value=10)\n                coll_timeout = st.number_input(\"Timeout collecteur (s)\", value=coll.get(\"collector_timeout\", 120), min_value=10)\n            with col2:\n                coll_max_items = st.number_input(\"Items max par source\", value=coll.get(\"max_items_per_source\", 100), min_value=10)\n                coll_dedup = st.number_input(\"Fenetre dedup (jours)\", value=coll.get(\"dedup_window_days\", 30), min_value=1)\n\n            st.divider()\n            st.subheader(\"ðŸŒ HTTP / Anti-WAF\")\n            st.caption(\"Headers envoyes avec chaque requete pour eviter les blocages (erreurs 403)\")\n\n            http = raw.get(\"http\", {})\n            col1, col2 = st.columns(2)\n            with col1:\n                http_timeout = st.number_input(\"HTTP timeout (s)\", value=http.get(\"timeout\", 30), min_value=5)\n                http_retries = st.number_input(\"HTTP retries\", value=http.get(\"max_retries\", 3), min_value=0)\n            with col2:\n                http_rate = st.number_input(\"Rate limit (req/s)\", value=float(http.get(\"rate_limit\", 2.0)), min_value=0.1, step=0.5)\n\n            st.markdown(\"**Headers navigateur**\")\n            http_ua = st.text_input(\n                \"User-Agent\",\n                value=http.get(\"user_agent\", DEFAULT_UA),\n                help=\"Identifiant du navigateur simule\"\n            )\n            http_accept = st.text_input(\n                \"Accept\",\n                value=http.get(\"accept\", DEFAULT_ACCEPT),\n                help=\"Types de contenu acceptes\"\n            )\n            http_accept_lang = st.text_input(\n                \"Accept-Language\",\n                value=http.get(\"accept_language\", DEFAULT_ACCEPT_LANG),\n                help=\"Langues preferees\"\n            )\n\n            with st.expander(\"ðŸ”§ Headers avances (Chrome/Chromium)\"):\n                col1, col2 = st.columns(2)\n                with col1:\n                    http_sec_ch_ua = st.text_input(\n                        \"Sec-Ch-Ua\",\n                        value=http.get(\"sec_ch_ua\", '\"Not_A Brand\";v=\"8\", \"Chromium\";v=\"120\", \"Google Chrome\";v=\"120\"'),\n                    )\n                    http_sec_ch_ua_mobile = st.text_input(\n                        \"Sec-Ch-Ua-Mobile\",\n                        value=http.get(\"sec_ch_ua_mobile\", \"?0\"),\n                    )\n                    http_sec_ch_ua_platform = st.text_input(\n                        \"Sec-Ch-Ua-Platform\",\n                        value=http.get(\"sec_ch_ua_platform\", '\"Windows\"'),\n                    )\n                    http_sec_fetch_dest = st.text_input(\n                        \"Sec-Fetch-Dest\",\n                        value=http.get(\"sec_fetch_dest\", \"document\"),\n                    )\n                with col2:\n                    http_sec_fetch_mode = st.text_input(\n                        \"Sec-Fetch-Mode\",\n                        value=http.get(\"sec_fetch_mode\", \"navigate\"),\n                    )\n                    http_sec_fetch_site = st.text_input(\n                        \"Sec-Fetch-Site\",\n                        value=http.get(\"sec_fetch_site\", \"none\"),\n                    )\n                    http_upgrade = st.text_input(\n                        \"Upgrade-Insecure-Requests\",\n                        value=http.get(\"upgrade_insecure_requests\", \"1\"),\n                    )\n                    http_dnt = st.text_input(\n                        \"DNT (Do Not Track)\",\n                        value=http.get(\"dnt\", \"1\"),\n                    )\n\n            with st.expander(\"ðŸ“ Headers personnalises (JSON)\"):\n                st.caption(\"Ajoutez des headers supplementaires au format JSON\")\n                custom_headers_default = http.get(\"custom_headers\", {})\n                http_custom_headers = st.text_area(\n                    \"Custom Headers\",\n                    value=_json_coll.dumps(custom_headers_default, indent=2) if custom_headers_default else \"{}\",\n                    height=100,\n                    placeholder='{\"X-Custom-Header\": \"value\"}',\n                )\n\n            st.divider()\n            st.subheader(\"Scheduler\")\n            sched = raw.get(\"scheduler\", {})\n            col1, col2 = st.columns(2)\n            with col1:\n                sched_enabled = st.checkbox(\"Scheduler actif\", value=sched.get(\"enabled\", True))\n                daily_time = st.text_input(\"Rapport quotidien (HH:MM)\", value=sched.get(\"daily_report_time\", \"08:00\"))\n            with col2:\n                weekly_day = st.number_input(\"Jour rapport hebdo (0=lun)\", value=sched.get(\"weekly_report_day\", 0), min_value=0, max_value=6)\n                weekly_time = st.text_input(\"Heure rapport hebdo\", value=sched.get(\"weekly_report_time\", \"09:00\"))\n\n            if st.form_submit_button(\"ðŸ’¾ Sauvegarder Collecte\", use_container_width=True):\n                # Parse custom headers\n                try:\n                    custom_headers_parsed = _json_coll.loads(http_custom_headers) if http_custom_headers.strip() else {}\n                except _json_coll.JSONDecodeError:\n                    custom_headers_parsed = {}\n                    st.warning(\"Headers personnalises JSON invalide, ignore\")\n\n                new_config = dict(raw)\n                new_config[\"collection\"] = {\n                    \"default_interval_minutes\": coll_interval,\n                    \"max_concurrent_collectors\": coll_concurrent,\n                    \"max_items_per_source\": coll_max_items,\n                    \"dedup_window_days\": coll_dedup,\n                    \"collector_timeout\": coll_timeout,\n                }\n                new_config[\"http\"] = {\n                    \"timeout\": http_timeout,\n                    \"max_retries\": http_retries,\n                    \"retry_delay\": raw.get(\"http\", {}).get(\"retry_delay\", 5),\n                    \"rate_limit\": http_rate,\n                    \"cache\": raw.get(\"http\", {}).get(\"cache\", {}),\n                    # Browser-like headers\n                    \"user_agent\": http_ua,\n                    \"accept\": http_accept,\n                    \"accept_language\": http_accept_lang,\n                    \"accept_encoding\": \"gzip, deflate, br\",\n                    \"cache_control\": \"no-cache\",\n                    # Sec-Ch headers\n                    \"sec_ch_ua\": http_sec_ch_ua,\n                    \"sec_ch_ua_mobile\": http_sec_ch_ua_mobile,\n                    \"sec_ch_ua_platform\": http_sec_ch_ua_platform,\n                    \"sec_fetch_dest\": http_sec_fetch_dest,\n                    \"sec_fetch_mode\": http_sec_fetch_mode,\n                    \"sec_fetch_site\": http_sec_fetch_site,\n                    \"sec_fetch_user\": \"?1\",\n                    \"upgrade_insecure_requests\": http_upgrade,\n                    \"dnt\": http_dnt,\n                    # Custom headers\n                    \"custom_headers\": custom_headers_parsed,\n                }\n                new_config[\"scheduler\"] = {\n                    \"enabled\": sched_enabled,\n                    \"check_interval_seconds\": sched.get(\"check_interval_seconds\", 60),\n                    \"daily_report_time\": daily_time,\n                    \"weekly_report_day\": weekly_day,\n                    \"weekly_report_time\": weekly_time,\n                }\n                try:\n                    _save_settings_yaml(new_config)\n                    st.success(\"Parametres de collecte sauvegardes !\")\n                    st.info(\"Redemarrez l'application pour appliquer les nouveaux headers HTTP\")\n                except Exception as e:\n                    st.error(f\"Erreur: {e}\")"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2164,"cache_read_input_tokens":163826,"output_tokens":3626,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":2164,"ephemeral_5m_input_tokens":0}}},"requestId":"req_011CXqZ8o97RrApxUHHBsbAN","type":"assistant","uuid":"42b37ab2-885a-404d-8e53-2c4982591045","timestamp":"2026-02-05T20:30:13.414Z"}
{"parentUuid":"42b37ab2-885a-404d-8e53-2c4982591045","isSidechain":true,"userType":"external","cwd":"/home/user/sentinelpi","sessionId":"fad99b44-7337-47f8-955b-2384ef483150","version":"2.1.31","gitBranch":"HEAD","agentId":"acompact-116d3d","slug":"reactive-humming-rainbow","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Biu2XqEs9SoVoZBj5AoRHh","type":"tool_result","content":"The file /home/user/sentinelpi/src/dashboard/app.py has been updated successfully."}]},"uuid":"6e57bc52-eb32-484f-915d-643a26a59e10","timestamp":"2026-02-05T20:30:13.482Z","toolUseResult":{"filePath":"/home/user/sentinelpi/src/dashboard/app.py","oldString":"    with tabs[1]:\n        with st.form(\"settings_collection\"):\n            col1, col2 = st.columns(2)\n            coll = raw.get(\"collection\", {})\n            with col1:\n                coll_interval = st.number_input(\"Intervalle par defaut (min)\", value=coll.get(\"default_interval_minutes\", 60), min_value=5)\n                coll_concurrent = st.number_input(\"Collecteurs simultanes\", value=coll.get(\"max_concurrent_collectors\", 3), min_value=1, max_value=10)\n                coll_timeout = st.number_input(\"Timeout collecteur (s)\", value=coll.get(\"collector_timeout\", 120), min_value=10)\n            with col2:\n                coll_max_items = st.number_input(\"Items max par source\", value=coll.get(\"max_items_per_source\", 100), min_value=10)\n                coll_dedup = st.number_input(\"Fenetre dedup (jours)\", value=coll.get(\"dedup_window_days\", 30), min_value=1)\n\n            st.divider()\n            http = raw.get(\"http\", {})\n            col1, col2 = st.columns(2)\n            with col1:\n                http_timeout = st.number_input(\"HTTP timeout (s)\", value=http.get(\"timeout\", 30), min_value=5)\n                http_retries = st.number_input(\"HTTP retries\", value=http.get(\"max_retries\", 3), min_value=0)\n            with col2:\n                http_rate = st.number_input(\"Rate limit (req/s)\", value=http.get(\"rate_limit\", 2), min_value=1)\n                http_ua = st.text_input(\"User-Agent\", value=http.get(\"user_agent\", \"\"))\n\n            st.divider()\n            st.subheader(\"Scheduler\")\n            sched = raw.get(\"scheduler\", {})\n            col1, col2 = st.columns(2)\n            with col1:\n                sched_enabled = st.checkbox(\"Scheduler actif\", value=sched.get(\"enabled\", True))\n                daily_time = st.text_input(\"Rapport quotidien (HH:MM)\", value=sched.get(\"daily_report_time\", \"08:00\"))\n            with col2:\n                weekly_day = st.number_input(\"Jour rapport hebdo (0=lun)\", value=sched.get(\"weekly_report_day\", 0), min_value=0, max_value=6)\n                weekly_time = st.text_input(\"Heure rapport hebdo\", value=sched.get(\"weekly_report_time\", \"09:00\"))\n\n            if st.form_submit_button(\"ðŸ’¾ Sauvegarder Collecte\", use_container_width=True):\n                new_config = dict(raw)\n                new_config[\"collection\"] = {\n                    \"default_interval_minutes\": coll_interval,\n                    \"max_concurrent_collectors\": coll_concurrent,\n                    \"max_items_per_source\": coll_max_items,\n                    \"dedup_window_days\": coll_dedup,\n                    \"collector_timeout\": coll_timeout,\n                }\n                new_config[\"http\"] = {\n                    \"timeout\": http_timeout, \"max_retries\": http_retries,\n                    \"retry_delay\": raw.get(\"http\", {}).get(\"retry_delay\", 5),\n                    \"user_agent\": http_ua, \"rate_limit\": http_rate,\n                    \"cache\": raw.get(\"http\", {}).get(\"cache\", {}),\n                }\n                new_config[\"scheduler\"] = {\n                    \"enabled\": sched_enabled,\n                    \"check_interval_seconds\": sched.get(\"check_interval_seconds\", 60),\n                    \"daily_report_time\": daily_time,\n                    \"weekly_report_day\": weekly_day,\n                    \"weekly_report_time\": weekly_time,\n                }\n                try:\n                    _save_settings_yaml(new_config)\n                    st.success(\"Parametres de collecte sauvegardes !\")\n                except Exception as e:\n                    st.error(f\"Erreur: {e}\")","newString":"    with tabs[1]:\n        import json as _json_coll\n\n        # Default browser-like headers\n        DEFAULT_UA = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n        DEFAULT_ACCEPT = \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\"\n        DEFAULT_ACCEPT_LANG = \"fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7\"\n\n        with st.form(\"settings_collection\"):\n            col1, col2 = st.columns(2)\n            coll = raw.get(\"collection\", {})\n            with col1:\n                coll_interval = st.number_input(\"Intervalle par defaut (min)\", value=coll.get(\"default_interval_minutes\", 60), min_value=5)\n                coll_concurrent = st.number_input(\"Collecteurs simultanes\", value=coll.get(\"max_concurrent_collectors\", 3), min_value=1, max_value=10)\n                coll_timeout = st.number_input(\"Timeout collecteur (s)\", value=coll.get(\"collector_timeout\", 120), min_value=10)\n            with col2:\n                coll_max_items = st.number_input(\"Items max par source\", value=coll.get(\"max_items_per_source\", 100), min_value=10)\n                coll_dedup = st.number_input(\"Fenetre dedup (jours)\", value=coll.get(\"dedup_window_days\", 30), min_value=1)\n\n            st.divider()\n            st.subheader(\"ðŸŒ HTTP / Anti-WAF\")\n            st.caption(\"Headers envoyes avec chaque requete pour eviter les blocages (erreurs 403)\")\n\n            http = raw.get(\"http\", {})\n            col1, col2 = st.columns(2)\n            with col1:\n                http_timeout = st.number_input(\"HTTP timeout (s)\", value=http.get(\"timeout\", 30), min_value=5)\n                http_retries = st.number_input(\"HTTP retries\", value=http.get(\"max_retries\", 3), min_value=0)\n            with col2:\n                http_rate = st.number_input(\"Rate limit (req/s)\", value=float(http.get(\"rate_limit\", 2.0)), min_value=0.1, step=0.5)\n\n            st.markdown(\"**Headers navigateur**\")\n            http_ua = st.text_input(\n                \"User-Agent\",\n                value=http.get(\"user_agent\", DEFAULT_UA),\n                help=\"Identifiant du navigateur simule\"\n            )\n            http_accept = st.text_input(\n                \"Accept\",\n                value=http.get(\"accept\", DEFAULT_ACCEPT),\n                help=\"Types de contenu acceptes\"\n            )\n            http_accept_lang = st.text_input(\n                \"Accept-Language\",\n                value=http.get(\"accept_language\", DEFAULT_ACCEPT_LANG),\n                help=\"Langues preferees\"\n            )\n\n            with st.expander(\"ðŸ”§ Headers avances (Chrome/Chromium)\"):\n                col1, col2 = st.columns(2)\n                with col1:\n                    http_sec_ch_ua = st.text_input(\n                        \"Sec-Ch-Ua\",\n                        value=http.get(\"sec_ch_ua\", '\"Not_A Brand\";v=\"8\", \"Chromium\";v=\"120\", \"Google Chrome\";v=\"120\"'),\n                    )\n                    http_sec_ch_ua_mobile = st.text_input(\n                        \"Sec-Ch-Ua-Mobile\",\n                        value=http.get(\"sec_ch_ua_mobile\", \"?0\"),\n                    )\n                    http_sec_ch_ua_platform = st.text_input(\n                        \"Sec-Ch-Ua-Platform\",\n                        value=http.get(\"sec_ch_ua_platform\", '\"Windows\"'),\n                    )\n                    http_sec_fetch_dest = st.text_input(\n                        \"Sec-Fetch-Dest\",\n                        value=http.get(\"sec_fetch_dest\", \"document\"),\n                    )\n                with col2:\n                    http_sec_fetch_mode = st.text_input(\n                        \"Sec-Fetch-Mode\",\n                        value=http.get(\"sec_fetch_mode\", \"navigate\"),\n                    )\n                    http_sec_fetch_site = st.text_input(\n                        \"Sec-Fetch-Site\",\n                        value=http.get(\"sec_fetch_site\", \"none\"),\n                    )\n                    http_upgrade = st.text_input(\n                        \"Upgrade-Insecure-Requests\",\n                        value=http.get(\"upgrade_insecure_requests\", \"1\"),\n                    )\n                    http_dnt = st.text_input(\n                        \"DNT (Do Not Track)\",\n                        value=http.get(\"dnt\", \"1\"),\n                    )\n\n            with st.expander(\"ðŸ“ Headers personnalises (JSON)\"):\n                st.caption(\"Ajoutez des headers supplementaires au format JSON\")\n                custom_headers_default = http.get(\"custom_headers\", {})\n                http_custom_headers = st.text_area(\n                    \"Custom Headers\",\n                    value=_json_coll.dumps(custom_headers_default, indent=2) if custom_headers_default else \"{}\",\n                    height=100,\n                    placeholder='{\"X-Custom-Header\": \"value\"}',\n                )\n\n            st.divider()\n            st.subheader(\"Scheduler\")\n            sched = raw.get(\"scheduler\", {})\n            col1, col2 = st.columns(2)\n            with col1:\n                sched_enabled = st.checkbox(\"Scheduler actif\", value=sched.get(\"enabled\", True))\n                daily_time = st.text_input(\"Rapport quotidien (HH:MM)\", value=sched.get(\"daily_report_time\", \"08:00\"))\n            with col2:\n                weekly_day = st.number_input(\"Jour rapport hebdo (0=lun)\", value=sched.get(\"weekly_report_day\", 0), min_value=0, max_value=6)\n                weekly_time = st.text_input(\"Heure rapport hebdo\", value=sched.get(\"weekly_report_time\", \"09:00\"))\n\n            if st.form_submit_button(\"ðŸ’¾ Sauvegarder Collecte\", use_container_width=True):\n                # Parse custom headers\n                try:\n                    custom_headers_parsed = _json_coll.loads(http_custom_headers) if http_custom_headers.strip() else {}\n                except _json_coll.JSONDecodeError:\n                    custom_headers_parsed = {}\n                    st.warning(\"Headers personnalises JSON invalide, ignore\")\n\n                new_config = dict(raw)\n                new_config[\"collection\"] = {\n                    \"default_interval_minutes\": coll_interval,\n                    \"max_concurrent_collectors\": coll_concurrent,\n                    \"max_items_per_source\": coll_max_items,\n                    \"dedup_window_days\": coll_dedup,\n                    \"collector_timeout\": coll_timeout,\n                }\n                new_config[\"http\"] = {\n                    \"timeout\": http_timeout,\n                    \"max_retries\": http_retries,\n                    \"retry_delay\": raw.get(\"http\", {}).get(\"retry_delay\", 5),\n                    \"rate_limit\": http_rate,\n                    \"cache\": raw.get(\"http\", {}).get(\"cache\", {}),\n                    # Browser-like headers\n                    \"user_agent\": http_ua,\n                    \"accept\": http_accept,\n                    \"accept_language\": http_accept_lang,\n                    \"accept_encoding\": \"gzip, deflate, br\",\n                    \"cache_control\": \"no-cache\",\n                    # Sec-Ch headers\n                    \"sec_ch_ua\": http_sec_ch_ua,\n                    \"sec_ch_ua_mobile\": http_sec_ch_ua_mobile,\n                    \"sec_ch_ua_platform\": http_sec_ch_ua_platform,\n                    \"sec_fetch_dest\": http_sec_fetch_dest,\n                    \"sec_fetch_mode\": http_sec_fetch_mode,\n                    \"sec_fetch_site\": http_sec_fetch_site,\n                    \"sec_fetch_user\": \"?1\",\n                    \"upgrade_insecure_requests\": http_upgrade,\n                    \"dnt\": http_dnt,\n                    # Custom headers\n                    \"custom_headers\": custom_headers_parsed,\n                }\n                new_config[\"scheduler\"] = {\n                    \"enabled\": sched_enabled,\n                    \"check_interval_seconds\": sched.get(\"check_interval_seconds\", 60),\n                    \"daily_report_time\": daily_time,\n                    \"weekly_report_day\": weekly_day,\n                    \"weekly_report_time\": weekly_time,\n                }\n                try:\n                    _save_settings_yaml(new_config)\n                    st.success(\"Parametres de collecte sauvegardes !\")\n                    st.info(\"Redemarrez l'application pour appliquer les nouveaux headers HTTP\")\n                except Exception as e:\n                    st.error(f\"Erreur: {e}\")","originalFile":"\"\"\"\nSentinelPi Dashboard - Main Streamlit application.\n\nProvides a web interface for monitoring and managing the watch station.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\nimport hashlib\nfrom datetime import datetime, timedelta\n\nimport streamlit as st\n\nfrom src.utils.config import get_settings\nfrom src.utils.logging import create_logger, setup_logging\n\nlog = create_logger(\"dashboard.app\")\n\n\ndef run_async(coro):\n    \"\"\"Run an async coroutine from sync context.\"\"\"\n    try:\n        loop = asyncio.get_event_loop()\n    except RuntimeError:\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n    return loop.run_until_complete(coro)\n\n\nasync def add_to_db(source):\n    \"\"\"Add a source to the database.\"\"\"\n    from src.storage.database import get_session\n    async with get_session() as session:\n        session.add(source)\n        await session.commit()\n\n\nasync def run_collection_now(source_id: str | None = None) -> dict:\n    \"\"\"\n    Run collection immediately for one or all enabled sources.\n\n    Returns dict with results summary.\n    \"\"\"\n    from src.storage.database import get_session, init_database\n    from src.storage.models import Source, Item, ItemStatus\n    from src.collectors import create_collector\n    from src.processors import Deduplicator, FilterEngine, Scorer, Enricher, load_filters_from_config\n    from sqlalchemy import select\n\n    await init_database()\n\n    async with get_session() as session:\n        if source_id:\n            result = await session.execute(select(Source).where(Source.id == source_id))\n            sources = [result.scalar_one_or_none()]\n            sources = [s for s in sources if s]\n        else:\n            result = await session.execute(select(Source).where(Source.enabled == True))\n            sources = result.scalars().all()\n\n    if not sources:\n        return {\"success\": False, \"message\": \"Aucune source trouvee\", \"items\": 0}\n\n    total_items = 0\n    errors = []\n\n    for source in sources:\n        try:\n            collector = create_collector(source)\n            items = []\n            async for item in collector.collect():\n                items.append(item)\n            total_items += len(items)\n\n            # Enrich items\n            from src.processors.enricher import Enricher\n            enricher = Enricher()\n\n            # Store items\n            from src.utils.dates import now as utc_now\n            async with get_session() as session:\n                for ci in items:\n                    # Check duplicate\n                    existing = await session.execute(\n                        select(Item.id).where(\n                            Item.guid == ci.guid,\n                            Item.source_id == source.id,\n                        )\n                    )\n                    if existing.scalar():\n                        continue\n\n                    # Enrich the item\n                    try:\n                        enrichment = enricher.enrich(ci)\n                    except Exception:\n                        enrichment = None\n\n                    db_item = Item()\n                    db_item.source_id = source.id\n                    db_item.guid = ci.guid\n                    db_item.content_hash = ci.content_hash\n                    db_item.title = ci.title\n                    db_item.url = ci.url\n                    db_item.author = ci.author\n                    db_item.content = ci.content\n                    db_item.summary = (ci.summary or (enrichment.summary if enrichment else None))\n                    db_item.published_at = ci.published_at\n                    db_item.collected_at = ci.collected_at\n                    db_item.image_url = ci.image_url\n                    db_item.language = (enrichment.language if enrichment else None) or ci.language\n                    db_item.keywords = enrichment.keywords if enrichment else []\n                    db_item.sentiment = enrichment.sentiment if enrichment else None\n                    db_item.sentiment_score = enrichment.sentiment_score if enrichment else None\n                    db_item.status = ItemStatus.NEW\n                    db_item.relevance_score = 50.0\n                    session.add(db_item)\n\n                # Update source last_check\n                src_result = await session.execute(select(Source).where(Source.id == source.id))\n                src_obj = src_result.scalar_one_or_none()\n                if src_obj:\n                    src_obj.last_check = utc_now()\n                    src_obj.last_success = utc_now()\n                    src_obj.consecutive_errors = 0\n\n                await session.commit()\n\n        except Exception as e:\n            errors.append(f\"{source.name}: {str(e)[:80]}\")\n\n    msg = f\"{total_items} items collectes depuis {len(sources)} source(s)\"\n    if errors:\n        msg += f\" ({len(errors)} erreur(s))\"\n\n    return {\"success\": True, \"message\": msg, \"items\": total_items, \"errors\": errors}\n\n\nasync def reset_database(keep_sources: bool = False) -> None:\n    \"\"\"Reset the database, optionally keeping sources and filters.\"\"\"\n    from src.storage.database import get_session, init_database\n    from src.storage.models import Item, Alert, Source, Filter\n    from sqlalchemy import delete\n\n    await init_database()\n\n    async with get_session() as session:\n        await session.execute(delete(Item))\n        await session.execute(delete(Alert))\n\n        if not keep_sources:\n            await session.execute(delete(Filter))\n            await session.execute(delete(Source))\n\n        await session.commit()\n\n\nasync def sync_sources_from_yaml():\n    \"\"\"Sync sources from YAML config to database.\"\"\"\n    from src.storage.database import get_session, init_database\n    from src.storage.models import Source, SourceType\n    from src.utils.config import load_sources_config\n    from sqlalchemy import select\n\n    # Ensure database is initialized\n    await init_database()\n\n    sources_config = load_sources_config()\n    sources_list = sources_config.get(\"sources\", [])\n\n    async with get_session() as session:\n        for config in sources_list:\n            # Generate deterministic ID from name + URL\n            source_key = f\"{config.get('name', '')}:{config.get('url', '')}\"\n            source_id = hashlib.sha256(source_key.encode()).hexdigest()[:32]\n\n            # Check if exists\n            result = await session.execute(\n                select(Source).where(Source.id == source_id)\n            )\n            existing = result.scalar_one_or_none()\n\n            if existing:\n                # Update\n                existing.name = config.get(\"name\", existing.name)\n                existing.url = config.get(\"url\", existing.url)\n                existing.enabled = config.get(\"enabled\", True)\n                existing.interval_minutes = config.get(\"interval_minutes\", 60)\n                existing.priority = config.get(\"priority\", 2)\n                existing.category = config.get(\"category\")\n                existing.tags = config.get(\"tags\", [])\n                existing.config = config.get(\"config\", {})\n            else:\n                # Create\n                source = Source()\n                source.id = source_id\n                source.name = config.get(\"name\", \"Unnamed\")\n                source.type = SourceType(config.get(\"type\", \"rss\"))\n                source.url = config.get(\"url\", \"\")\n                source.enabled = config.get(\"enabled\", True)\n                source.interval_minutes = config.get(\"interval_minutes\", 60)\n                source.priority = config.get(\"priority\", 2)\n                source.category = config.get(\"category\")\n                source.tags = config.get(\"tags\", [])\n                source.config = config.get(\"config\", {})\n                session.add(source)\n\n        await session.commit()\n\n    return len(sources_list)\n\n\nasync def sync_filters_from_yaml():\n    \"\"\"Sync filters from YAML config to database.\"\"\"\n    from src.storage.database import get_session, init_database\n    from src.storage.models import Filter, FilterAction\n    from src.utils.config import load_filters_config\n    from sqlalchemy import select\n\n    # Ensure database is initialized\n    await init_database()\n\n    filters_config = load_filters_config()\n    filters_list = filters_config.get(\"filters\", [])\n\n    async with get_session() as session:\n        for config in filters_list:\n            # Generate deterministic ID from name\n            filter_name = config.get(\"name\", \"\")\n            filter_id = hashlib.sha256(filter_name.encode()).hexdigest()[:32]\n\n            # Check if exists\n            result = await session.execute(\n                select(Filter).where(Filter.id == filter_id)\n            )\n            existing = result.scalar_one_or_none()\n\n            if existing:\n                # Update\n                existing.name = config.get(\"name\", existing.name)\n                existing.description = config.get(\"description\")\n                existing.action = FilterAction(config.get(\"action\", \"include\"))\n                existing.action_params = config.get(\"action_params\", {})\n                existing.conditions = config.get(\"conditions\", {})\n                existing.score_modifier = config.get(\"score_modifier\", 0)\n                existing.priority = config.get(\"priority\", 100)\n                existing.enabled = config.get(\"enabled\", True)\n            else:\n                # Create\n                filter_obj = Filter()\n                filter_obj.id = filter_id\n                filter_obj.name = config.get(\"name\", \"Unnamed\")\n                filter_obj.description = config.get(\"description\")\n                filter_obj.action = FilterAction(config.get(\"action\", \"include\"))\n                filter_obj.action_params = config.get(\"action_params\", {})\n                filter_obj.conditions = config.get(\"conditions\", {})\n                filter_obj.score_modifier = config.get(\"score_modifier\", 0)\n                filter_obj.priority = config.get(\"priority\", 100)\n                filter_obj.enabled = config.get(\"enabled\", True)\n                session.add(filter_obj)\n\n        await session.commit()\n\n    return len(filters_list)\n\n\nasync def _get_sidebar_stats():\n    \"\"\"Get quick stats for the sidebar.\"\"\"\n    from src.storage.database import get_session, init_database\n    from src.storage.models import Source, Item, Alert, ItemStatus\n    from sqlalchemy import select, func\n    from datetime import datetime, timedelta, timezone\n\n    await init_database()\n\n    now = datetime.now(timezone.utc)\n    cutoff_24h = now - timedelta(hours=24)\n\n    async with get_session() as session:\n        # Active sources\n        result = await session.execute(\n            select(func.count(Source.id)).where(Source.enabled == True)\n        )\n        sources = result.scalar() or 0\n\n        # Items last 24h\n        result = await session.execute(\n            select(func.count(Item.id)).where(Item.collected_at >= cutoff_24h)\n        )\n        items_24h = result.scalar() or 0\n\n        # Alerts last 24h\n        result = await session.execute(\n            select(func.count(Alert.id)).where(Alert.created_at >= cutoff_24h)\n        )\n        alerts = result.scalar() or 0\n\n        # Unread items\n        result = await session.execute(\n            select(func.count(Item.id)).where(Item.status == ItemStatus.NEW)\n        )\n        unread = result.scalar() or 0\n\n    return {\n        \"sources\": sources,\n        \"items_24h\": items_24h,\n        \"alerts\": alerts,\n        \"unread\": unread,\n    }\n\n\nasync def _update_filter_db(filter_id, name, desc, action, action_params, conditions, score_mod, priority, enabled):\n    \"\"\"Update a filter in the database.\"\"\"\n    from src.storage.database import get_session\n    from src.storage.models import Filter, FilterAction\n    from sqlalchemy import select\n\n    async with get_session() as session:\n        result = await session.execute(select(Filter).where(Filter.id == filter_id))\n        f = result.scalar_one_or_none()\n        if f:\n            f.name = name\n            f.description = desc\n            f.action = FilterAction(action)\n            f.action_params = action_params\n            f.conditions = conditions\n            f.score_modifier = score_mod\n            f.priority = priority\n            f.enabled = enabled\n            await session.commit()\n\n\nasync def get_all_sources():\n    \"\"\"Get all sources from the database.\"\"\"\n    from src.storage.database import get_session\n    from src.storage.models import Source\n    from sqlalchemy import select\n\n    async with get_session() as session:\n        result = await session.execute(select(Source).order_by(Source.name))\n        return result.scalars().all()\n\n\nasync def get_all_filters():\n    \"\"\"Get all filters from the database.\"\"\"\n    from src.storage.database import get_session\n    from src.storage.models import Filter\n    from sqlalchemy import select\n\n    async with get_session() as session:\n        result = await session.execute(select(Filter).order_by(Filter.priority))\n        return result.scalars().all()\n\n\nasync def get_all_alerts(severity_filter=None, date_filter=None, limit=50):\n    \"\"\"Get alerts from the database.\"\"\"\n    from src.storage.database import get_session\n    from src.storage.models import Alert, AlertSeverity\n    from sqlalchemy import select, and_\n    from datetime import datetime, timedelta, timezone\n\n    async with get_session() as session:\n        query = select(Alert).order_by(Alert.created_at.desc()).limit(limit)\n\n        conditions = []\n\n        if severity_filter and severity_filter != \"all\":\n            conditions.append(Alert.severity == AlertSeverity(severity_filter))\n\n        if date_filter:\n            now = datetime.now(timezone.utc)\n            if date_filter == \"today\":\n                cutoff = now - timedelta(days=1)\n            elif date_filter == \"week\":\n                cutoff = now - timedelta(days=7)\n            elif date_filter == \"month\":\n                cutoff = now - timedelta(days=30)\n            else:\n                cutoff = None\n\n            if cutoff:\n                conditions.append(Alert.created_at >= cutoff)\n\n        if conditions:\n            query = query.where(and_(*conditions))\n\n        result = await session.execute(query)\n        return result.scalars().all()\n\n\nasync def get_stats(period=\"week\"):\n    \"\"\"Get statistics for the dashboard.\"\"\"\n    from src.storage.database import get_session, get_database_stats\n    from src.storage.models import Item, Alert, Source, ItemStatus, AlertSeverity\n    from sqlalchemy import select, func, cast, Date\n    from datetime import datetime, timedelta, timezone\n\n    now_utc = datetime.now(timezone.utc)\n    days_map = {\"week\": 7, \"month\": 30, \"quarter\": 90, \"year\": 365}\n    days = days_map.get(period, 7)\n    cutoff = now_utc - timedelta(days=days)\n\n    async with get_session() as session:\n        # Items count\n        result = await session.execute(\n            select(func.count(Item.id)).where(Item.collected_at >= cutoff)\n        )\n        items_count = result.scalar() or 0\n\n        # Alerts count\n        result = await session.execute(\n            select(func.count(Alert.id)).where(Alert.created_at >= cutoff)\n        )\n        alerts_count = result.scalar() or 0\n\n        # Active sources\n        result = await session.execute(\n            select(func.count(Source.id)).where(Source.enabled == True)\n        )\n        sources_count = result.scalar() or 0\n\n        # Unread items\n        result = await session.execute(\n            select(func.count(Item.id)).where(Item.status == ItemStatus.NEW)\n        )\n        unread_count = result.scalar() or 0\n\n        # Top items\n        result = await session.execute(\n            select(Item, Source.name)\n            .join(Source, Source.id == Item.source_id)\n            .where(Item.collected_at >= cutoff)\n            .order_by(Item.relevance_score.desc())\n            .limit(10)\n        )\n        top_items = result.all()\n\n        # Items by source\n        result = await session.execute(\n            select(Source.name, func.count(Item.id).label(\"count\"))\n            .join(Item, Item.source_id == Source.id)\n            .where(Item.collected_at >= cutoff)\n            .group_by(Source.id)\n            .order_by(func.count(Item.id).desc())\n            .limit(10)\n        )\n        items_by_source = result.all()\n\n        # Items by category\n        result = await session.execute(\n            select(Source.category, func.count(Item.id).label(\"count\"))\n            .join(Item, Item.source_id == Source.id)\n            .where(Item.collected_at >= cutoff, Source.category.isnot(None))\n            .group_by(Source.category)\n            .order_by(func.count(Item.id).desc())\n        )\n        items_by_category = result.all()\n\n        # Items per day\n        items_per_day = []\n        for i in range(days, 0, -1):\n            day_start = (now_utc - timedelta(days=i)).replace(hour=0, minute=0, second=0, microsecond=0)\n            day_end = day_start + timedelta(days=1)\n            result = await session.execute(\n                select(func.count(Item.id)).where(\n                    Item.collected_at >= day_start,\n                    Item.collected_at < day_end,\n                )\n            )\n            count = result.scalar() or 0\n            items_per_day.append({\n                \"date\": day_start.strftime(\"%d/%m\"),\n                \"count\": count,\n            })\n\n        # Alerts by severity\n        alerts_by_severity = {}\n        for sev in AlertSeverity:\n            result = await session.execute(\n                select(func.count(Alert.id)).where(\n                    Alert.created_at >= cutoff,\n                    Alert.severity == sev,\n                )\n            )\n            alerts_by_severity[sev.value] = result.scalar() or 0\n\n        # Sources health\n        result = await session.execute(select(Source).where(Source.enabled == True))\n        all_sources = result.scalars().all()\n        sources_healthy = sum(1 for s in all_sources if s.consecutive_errors == 0)\n        sources_error = sum(1 for s in all_sources if s.consecutive_errors > 0)\n        last_collection = max((s.last_success for s in all_sources if s.last_success), default=None)\n\n        # Keywords frequency\n        result = await session.execute(\n            select(Item.keywords_json)\n            .where(Item.collected_at >= cutoff, Item.keywords_json.isnot(None))\n            .limit(500)\n        )\n        keyword_rows = result.scalars().all()\n        from collections import Counter\n        import json\n        kw_counter = Counter()\n        for kw_json in keyword_rows:\n            try:\n                kws = json.loads(kw_json)\n                if isinstance(kws, list):\n                    kw_counter.update(kws)\n            except (json.JSONDecodeError, TypeError):\n                pass\n        top_keywords = kw_counter.most_common(20)\n\n        # DB stats\n        try:\n            db_stats = await get_database_stats()\n        except Exception:\n            db_stats = {\"size_mb\": 0}\n\n        return {\n            \"items_count\": items_count,\n            \"alerts_count\": alerts_count,\n            \"sources_count\": sources_count,\n            \"unread_count\": unread_count,\n            \"top_items\": top_items,\n            \"items_by_source\": items_by_source,\n            \"items_by_category\": items_by_category,\n            \"items_per_day\": items_per_day,\n            \"alerts_by_severity\": alerts_by_severity,\n            \"sources_healthy\": sources_healthy,\n            \"sources_error\": sources_error,\n            \"last_collection\": last_collection,\n            \"top_keywords\": top_keywords,\n            \"db_size_mb\": db_stats.get(\"size_mb\", 0),\n        }\n\n\ndef _parse_search_query(search: str, Item):\n    \"\"\"\n    Parse a search query with operators into SQLAlchemy conditions.\n\n    Supports:\n    - \"exact phrase\" : exact match\n    - AND / ET       : both terms required (default between terms)\n    - OR / OU        : either term\n    - NOT / -term    : exclude term\n    \"\"\"\n    import re as _re\n    from sqlalchemy import and_, or_, not_\n\n    # Extract quoted phrases first\n    phrases = _re.findall(r'\"([^\"]+)\"', search)\n    remaining = _re.sub(r'\"[^\"]*\"', '', search).strip()\n\n    # Split remaining by OR/OU\n    or_groups = _re.split(r'\\s+(?:OR|OU)\\s+', remaining, flags=_re.IGNORECASE)\n\n    all_conditions = []\n\n    for group in or_groups:\n        group_conditions = []\n\n        # Split by AND/ET or whitespace (implicit AND)\n        terms = _re.split(r'\\s+(?:AND|ET)\\s+|\\s+', group, flags=_re.IGNORECASE)\n\n        for term in terms:\n            term = term.strip()\n            if not term:\n                continue\n\n            # NOT / - prefix\n            negate = False\n            if term.upper() in (\"NOT\", \"NON\"):\n                continue  # skip, will be handled with next term\n            if term.startswith(\"-\"):\n                negate = True\n                term = term[1:]\n            if not term:\n                continue\n\n            pattern = f\"%{term}%\"\n            cond = (Item.title.ilike(pattern)) | (Item.content.ilike(pattern))\n\n            if negate:\n                cond = not_(cond)\n\n            group_conditions.append(cond)\n\n        if group_conditions:\n            all_conditions.append(and_(*group_conditions))\n\n    # Add quoted phrase conditions\n    for phrase in phrases:\n        pattern = f\"%{phrase}%\"\n        all_conditions.append(\n            (Item.title.ilike(pattern)) | (Item.content.ilike(pattern))\n        )\n\n    if not all_conditions:\n        return None\n\n    if len(all_conditions) == 1:\n        return all_conditions[0]\n\n    # If we had OR groups, combine with OR; otherwise AND\n    if len(or_groups) > 1 or phrases:\n        return or_(*all_conditions)\n    return and_(*all_conditions)\n\n\nasync def get_feed_items(search=None, category=None, date_from=None, date_to=None, status_filter=None, source_id=None, filter_id=None, sort_by=\"date\", limit=100):\n    \"\"\"Get items for the feed page.\"\"\"\n    from src.storage.database import get_session\n    from src.storage.models import Item, Source, ItemStatus\n    from sqlalchemy import select, and_\n    from datetime import datetime, timedelta, timezone\n\n    async with get_session() as session:\n        # Build query with join for source filtering\n        query = select(Item)\n\n        conditions = []\n\n        # Source filter\n        if source_id:\n            conditions.append(Item.source_id == source_id)\n\n        # Category filter (requires join)\n        if category:\n            subquery = select(Source.id).where(Source.category == category)\n            conditions.append(Item.source_id.in_(subquery))\n\n        # Filter (rule) filter - items that matched a specific filter\n        if filter_id:\n            # matched_filters_json contains a JSON array of filter IDs\n            # Use LIKE to search for the filter ID in the JSON string\n            conditions.append(Item.matched_filters_json.like(f'%\"{filter_id}\"%'))\n\n        # Status filter\n        if status_filter == \"starred\":\n            conditions.append(Item.starred == True)\n        elif status_filter == \"unread\":\n            conditions.append(Item.status == ItemStatus.NEW)\n        elif status_filter == \"read\":\n            conditions.append(Item.status == ItemStatus.READ)\n        elif status_filter == \"archived\":\n            conditions.append(Item.status == ItemStatus.ARCHIVED)\n\n        # Date range filter\n        if date_from:\n            dt_from = datetime(date_from.year, date_from.month, date_from.day, tzinfo=timezone.utc)\n            conditions.append(Item.collected_at >= dt_from)\n        if date_to:\n            dt_to = datetime(date_to.year, date_to.month, date_to.day, 23, 59, 59, tzinfo=timezone.utc)\n            conditions.append(Item.collected_at <= dt_to)\n\n        # Search filter with operators (AND, OR, NOT, \"exact phrase\")\n        if search:\n            import re as _re\n            search_conditions = _parse_search_query(search, Item)\n            if search_conditions is not None:\n                conditions.append(search_conditions)\n\n        if conditions:\n            query = query.where(and_(*conditions))\n\n        # Sorting\n        if sort_by == \"score\":\n            query = query.order_by(Item.relevance_score.desc())\n        elif sort_by == \"date_asc\":\n            query = query.order_by(Item.collected_at.asc())\n        else:  # date (default)\n            query = query.order_by(Item.collected_at.desc())\n\n        query = query.limit(limit)\n\n        result = await session.execute(query)\n        items = result.scalars().all()\n\n        # Get sources dict\n        source_ids = set(item.source_id for item in items)\n        sources_dict = {}\n        if source_ids:\n            result = await session.execute(\n                select(Source).where(Source.id.in_(source_ids))\n            )\n            for source in result.scalars().all():\n                sources_dict[source.id] = source\n\n        return items, sources_dict\n\n# Page configuration\nst.set_page_config(\n    page_title=\"SentinelPi\",\n    page_icon=\"ðŸ›¡ï¸\",\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\",\n)\n\n\ndef init_session_state() -> None:\n    \"\"\"Initialize session state variables.\"\"\"\n    if \"initialized\" not in st.session_state:\n        st.session_state.initialized = True\n        st.session_state.current_page = \"feed\"\n        st.session_state.selected_source = None\n        st.session_state.selected_category = \"all\"\n        st.session_state.search_query = \"\"\n        st.session_state.date_filter = \"all\"\n        st.session_state.status_filter = \"all\"\n\n        # Sync sources and filters from YAML to database on first load\n        try:\n            sources_count = run_async(sync_sources_from_yaml())\n            log.info(f\"Synced {sources_count} sources from YAML to database\")\n        except Exception as e:\n            log.error(f\"Failed to sync sources: {e}\")\n\n        try:\n            filters_count = run_async(sync_filters_from_yaml())\n            log.info(f\"Synced {filters_count} filters from YAML to database\")\n        except Exception as e:\n            log.error(f\"Failed to sync filters: {e}\")\n\n\ndef render_sidebar() -> str:\n    \"\"\"Render the sidebar navigation with modern styled buttons.\"\"\"\n    read_only = st.session_state.get(\"read_only\", False)\n\n    if \"current_page\" not in st.session_state:\n        st.session_state.current_page = \"feed\"\n\n    # Navigation items\n    if read_only:\n        nav_items = [\n            (\"feed\", \"ðŸ“°\", \"Flux\"),\n            (\"stats\", \"ðŸ“Š\", \"Stats\"),\n            (\"docs\", \"ðŸ“š\", \"Docs\"),\n        ]\n    else:\n        nav_items = [\n            (\"feed\", \"ðŸ“°\", \"Flux\"),\n            (\"sources\", \"ðŸ“¡\", \"Sources\"),\n            (\"filters\", \"ðŸŽ¯\", \"Filtres\"),\n            (\"alerts\", \"ðŸ””\", \"Alertes\"),\n            (\"stats\", \"ðŸ“Š\", \"Stats\"),\n            (\"settings\", \"âš™ï¸\", \"Config\"),\n            (\"docs\", \"ðŸ“š\", \"Docs\"),\n        ]\n\n    with st.sidebar:\n        # Logo / brand\n        st.markdown(\n            '<div style=\"text-align:center;padding:0.5rem 0 0.2rem 0;\">'\n            '<span style=\"font-size:1.6rem;\">ðŸ›¡ï¸</span><br>'\n            '<span style=\"font-size:1.1rem;font-weight:700;letter-spacing:0.5px;\">SentinelPi</span>'\n            '</div>',\n            unsafe_allow_html=True,\n        )\n\n        if read_only:\n            st.markdown(\n                '<div style=\"text-align:center;margin-bottom:0.3rem;\">'\n                '<span style=\"background:#ffeeba;color:#856404;padding:2px 10px;'\n                'border-radius:10px;font-size:0.75rem;\">ðŸ”’ Lecture seule</span></div>',\n                unsafe_allow_html=True,\n            )\n        else:\n            st.markdown(\n                '<div style=\"text-align:center;margin-bottom:0.3rem;\">'\n                '<span style=\"background:#d4edda;color:#155724;padding:2px 10px;'\n                'border-radius:10px;font-size:0.75rem;\">â— En ligne</span></div>',\n                unsafe_allow_html=True,\n            )\n\n        st.markdown('<div style=\"margin:0.4rem 0;\">', unsafe_allow_html=True)\n\n        # Navigation buttons\n        for key, icon, label in nav_items:\n            is_active = st.session_state.current_page == key\n            if is_active:\n                style = (\n                    \"background:linear-gradient(90deg,#4f8bf9,#3a6fd8);color:#fff;\"\n                    \"border:none;border-radius:8px;padding:0.5rem 0.75rem;\"\n                    \"font-size:0.9rem;font-weight:600;width:100%;text-align:left;\"\n                    \"cursor:pointer;margin-bottom:2px;display:block;\"\n                    \"box-shadow:0 2px 6px rgba(79,139,249,0.3);\"\n                )\n            else:\n                style = (\n                    \"background:transparent;color:inherit;\"\n                    \"border:none;border-radius:8px;padding:0.5rem 0.75rem;\"\n                    \"font-size:0.9rem;width:100%;text-align:left;\"\n                    \"cursor:pointer;margin-bottom:2px;display:block;\"\n                )\n\n            # Use st.button for interactivity, styled via markdown above\n            if st.button(\n                f\"{icon}  {label}\",\n                key=f\"nav_{key}\",\n                use_container_width=True,\n                type=\"primary\" if is_active else \"secondary\",\n            ):\n                st.session_state.current_page = key\n                st.rerun()\n\n        st.markdown('</div>', unsafe_allow_html=True)\n\n        # Quick stats badges\n        try:\n            sidebar_stats = run_async(_get_sidebar_stats())\n        except Exception:\n            sidebar_stats = {\"sources\": 0, \"items_24h\": 0, \"alerts\": 0, \"unread\": 0}\n\n        st.markdown(\n            '<div style=\"display:flex;justify-content:space-around;'\n            'padding:0.6rem 0;margin-top:0.3rem;'\n            'background:rgba(128,128,128,0.06);border-radius:8px;\">'\n            f'<div style=\"text-align:center;line-height:1.2;\">'\n            f'<div style=\"font-size:1rem;font-weight:700;\">{sidebar_stats[\"sources\"]}</div>'\n            f'<div style=\"font-size:0.65rem;opacity:0.6;\">Sources</div></div>'\n            f'<div style=\"text-align:center;line-height:1.2;\">'\n            f'<div style=\"font-size:1rem;font-weight:700;\">{sidebar_stats[\"items_24h\"]}</div>'\n            f'<div style=\"font-size:0.65rem;opacity:0.6;\">Items/24h</div></div>'\n            f'<div style=\"text-align:center;line-height:1.2;\">'\n            f'<div style=\"font-size:1rem;font-weight:700;\">{sidebar_stats[\"alerts\"]}</div>'\n            f'<div style=\"font-size:0.65rem;opacity:0.6;\">Alertes</div></div>'\n            f'<div style=\"text-align:center;line-height:1.2;\">'\n            f'<div style=\"font-size:1rem;font-weight:700;\">{sidebar_stats[\"unread\"]}</div>'\n            f'<div style=\"font-size:0.65rem;opacity:0.6;\">Non lus</div></div>'\n            '</div>',\n            unsafe_allow_html=True,\n        )\n\n        # Login prompt in read-only mode\n        if read_only:\n            st.markdown(\"\")\n            with st.expander(\"ðŸ”“ Acces complet\"):\n                pw = st.text_input(\"Mot de passe\", type=\"password\", key=\"sidebar_pw\")\n                if st.button(\"Se connecter\", use_container_width=True):\n                    raw = _load_settings_yaml()\n                    stored_hash = raw.get(\"dashboard\", {}).get(\"password_hash\", \"\")\n                    if stored_hash and _check_password(pw, stored_hash):\n                        st.session_state.authenticated = True\n                        st.session_state.read_only = False\n                        st.rerun()\n                    else:\n                        st.error(\"Incorrect\")\n\n        # Version at bottom\n        settings = get_settings()\n        st.markdown(\n            f'<div style=\"text-align:center;padding-top:0.5rem;opacity:0.4;font-size:0.7rem;\">'\n            f'v{settings.app.version}</div>',\n            unsafe_allow_html=True,\n        )\n\n        return st.session_state.current_page\n\n\ndef render_feed_page() -> None:\n    \"\"\"Render the main feed page.\"\"\"\n    st.header(\"ðŸ“° Flux d'actualitÃ©s\")\n\n    from datetime import date as date_type, timedelta as td\n\n    today = date_type.today()\n\n    # Load available sources for filter\n    all_sources = run_async(get_all_sources())\n    source_options = {\"all\": \"Toutes les sources\"}\n    for src in all_sources:\n        source_options[src.id] = f\"{src.name}\"\n\n    # Load available filters for filter selector\n    all_filters = run_async(get_all_filters())\n    filter_options = {\"all\": \"Tous les filtres\"}\n    for flt in all_filters:\n        action_icon = {\n            \"alert\": \"ðŸ””\",\n            \"highlight\": \"âœ¨\",\n            \"tag\": \"ðŸ·ï¸\",\n            \"exclude\": \"ðŸš«\",\n            \"include\": \"âœ…\",\n        }.get(flt.action.value if hasattr(flt.action, \"value\") else flt.action, \"ðŸŽ¯\")\n        filter_options[flt.id] = f\"{action_icon} {flt.name}\"\n\n    # Row 1: Full-width search bar\n    search = st.text_input(\n        \"ðŸ” Rechercher\",\n        placeholder=\"Recherche... (AND, OR, NOT, \\\"phrase exacte\\\")\",\n        label_visibility=\"collapsed\",\n    )\n\n    # Row 2: Filters\n    col_status, col_source, col_filter, col_cat, col_sort, col_date, col_refresh = st.columns([0.9, 1.2, 1.2, 0.9, 0.7, 1.6, 0.3])\n\n    with col_status:\n        status_filter = st.selectbox(\n            \"Statut\",\n            options=[\"all\", \"unread\", \"starred\", \"read\", \"archived\"],\n            format_func=lambda x: {\n                \"all\": \"Tous\",\n                \"unread\": \"ðŸ†• Non lus\",\n                \"starred\": \"â­ Favoris\",\n                \"read\": \"âœ… Lus\",\n                \"archived\": \"ðŸ“ Archives\",\n            }.get(x, x),\n            label_visibility=\"collapsed\",\n        )\n\n    with col_source:\n        source_filter = st.selectbox(\n            \"Source\",\n            options=list(source_options.keys()),\n            format_func=lambda x: source_options.get(x, x),\n            label_visibility=\"collapsed\",\n        )\n\n    with col_filter:\n        filter_filter = st.selectbox(\n            \"Filtre\",\n            options=list(filter_options.keys()),\n            format_func=lambda x: filter_options.get(x, x),\n            label_visibility=\"collapsed\",\n            help=\"Afficher uniquement les items qui ont matche ce filtre\",\n        )\n\n    with col_cat:\n        # Get unique categories from sources\n        categories = sorted(set(s.category for s in all_sources if s.category))\n        cat_options = [\"all\"] + categories\n        category = st.selectbox(\n            \"CatÃ©gorie\",\n            options=cat_options,\n            format_func=lambda x: \"Toutes cat.\" if x == \"all\" else x.capitalize(),\n            label_visibility=\"collapsed\",\n        )\n\n    with col_sort:\n        sort_by = st.selectbox(\n            \"Tri\",\n            options=[\"date\", \"date_asc\", \"score\"],\n            format_func=lambda x: {\n                \"date\": \"ðŸ“… Recent\",\n                \"date_asc\": \"ðŸ“… Ancien\",\n                \"score\": \"â­ Score\",\n            }.get(x, x),\n            label_visibility=\"collapsed\",\n        )\n\n    with col_date:\n        default_range = (today - td(days=7), today)\n        date_range = st.date_input(\n            \"ðŸ“… Periode\",\n            value=default_range,\n            max_value=today,\n            label_visibility=\"collapsed\",\n        )\n\n    with col_refresh:\n        if st.button(\"ðŸ”„\", use_container_width=True, help=\"Actualiser\"):\n            st.rerun()\n\n    # Parse range (can be single date or tuple)\n    if isinstance(date_range, (list, tuple)) and len(date_range) == 2:\n        date_from, date_to = date_range\n    elif isinstance(date_range, (list, tuple)) and len(date_range) == 1:\n        date_from = date_range[0]\n        date_to = today\n    else:\n        date_from = date_range\n        date_to = today\n\n    st.divider()\n\n    # Load items from database\n    items, sources_dict = run_async(get_feed_items(\n        search=search if search else None,\n        category=category if category != \"all\" else None,\n        date_from=date_from,\n        date_to=date_to,\n        status_filter=status_filter if status_filter != \"all\" else None,\n        source_id=source_filter if source_filter != \"all\" else None,\n        filter_id=filter_filter if filter_filter != \"all\" else None,\n        sort_by=sort_by,\n    ))\n\n    if items:\n        st.caption(f\"{len(items)} items\")\n        from src.dashboard.components.feed import render_feed\n        read_only = st.session_state.get(\"read_only\", False)\n        render_feed(items, sources_dict, show_actions=not read_only)\n    else:\n        st.info(\"ðŸ“­ Aucun item Ã  afficher.\", icon=\"â„¹ï¸\")\n        with st.expander(\"ðŸ’¡ Comment dÃ©marrer\", expanded=True):\n            st.markdown(\"\"\"\n            1. **Ajoutez des sources** dans l'onglet ðŸ“¡ Sources\n            2. **Configurez des filtres** dans l'onglet ðŸŽ¯ Filtres\n            3. **Lancez la collecte** avec la commande `sentinelpi`\n            4. Les nouveaux articles apparaÃ®tront ici automatiquement\n            \"\"\")\n\n\n@st.dialog(\"Ajouter une source\")\ndef add_source_dialog():\n    \"\"\"Dialog for adding a new source.\"\"\"\n    source_type = st.selectbox(\n        \"Type\",\n        options=[\"rss\", \"web\", \"reddit\", \"mastodon\", \"youtube\", \"custom\"],\n    )\n\n    name = st.text_input(\"Nom\", placeholder=\"Ma nouvelle source\")\n    url = st.text_input(\"URL\", placeholder=\"https://...\")\n    category = st.text_input(\"CatÃ©gorie\", placeholder=\"tech, presse, etc.\")\n    interval = st.number_input(\"Intervalle (minutes)\", min_value=5, value=60)\n\n    col1, col2 = st.columns(2)\n    with col1:\n        if st.button(\"ðŸ’¾ Enregistrer\", use_container_width=True):\n            if name and url:\n                try:\n                    from src.storage.models import Source, SourceType\n\n                    source_key = f\"{name}:{url}\"\n                    source_id = hashlib.sha256(source_key.encode()).hexdigest()[:32]\n\n                    new_source = Source()\n                    new_source.id = source_id\n                    new_source.name = name\n                    new_source.type = SourceType(source_type)\n                    new_source.url = url\n                    new_source.category = category if category else None\n                    new_source.interval_minutes = interval\n                    new_source.enabled = True\n                    new_source.priority = 2\n                    new_source.config = {}\n\n                    run_async(add_to_db(new_source))\n                    st.rerun()\n                except Exception as e:\n                    st.error(f\"Erreur: {e}\")\n            else:\n                st.warning(\"Nom et URL requis\")\n    with col2:\n        if st.button(\"âŒ Annuler\", use_container_width=True):\n            st.rerun()\n\n\n@st.dialog(\"Modifier la source\", width=\"large\")\ndef edit_source_dialog(source):\n    \"\"\"Dialog for editing an existing source.\"\"\"\n    from src.dashboard.components.sources import _update_source, _run_async\n\n    source_type = source.type.value if hasattr(source.type, \"value\") else source.type\n\n    col1, col2 = st.columns(2)\n\n    with col1:\n        st.text_input(\"Type\", value=source_type.upper(), disabled=True)\n        name = st.text_input(\"Nom\", value=source.name, key=\"edit_src_name\")\n        url = st.text_input(\"URL\", value=source.url, key=\"edit_src_url\")\n        category = st.text_input(\n            \"CatÃ©gorie\",\n            value=source.category or \"\",\n            placeholder=\"tech, presse, etc.\",\n            key=\"edit_src_cat\",\n        )\n\n    with col2:\n        interval = st.number_input(\n            \"Intervalle (minutes)\",\n            min_value=5,\n            max_value=1440,\n            value=source.interval_minutes,\n            key=\"edit_src_interval\",\n        )\n        priority = st.selectbox(\n            \"PrioritÃ©\",\n            options=[1, 2, 3],\n            index=source.priority - 1,\n            format_func=lambda x: {1: \"ðŸ”´ Haute\", 2: \"ðŸŸ¡ Normale\", 3: \"ðŸŸ¢ Basse\"}.get(x),\n            key=\"edit_src_priority\",\n        )\n        enabled = st.checkbox(\"ActivÃ©e\", value=source.enabled, key=\"edit_src_enabled\")\n        tags_str = st.text_input(\n            \"Tags (virgules)\",\n            value=\", \".join(source.tags) if source.tags else \"\",\n            key=\"edit_src_tags\",\n        )\n\n    # Configuration spÃ©cifique (JSON)\n    with st.expander(\"Configuration avancÃ©e\"):\n        import json\n        config_str = st.text_area(\n            \"Configuration (JSON)\",\n            value=json.dumps(source.config, indent=2, ensure_ascii=False) if source.config else \"{}\",\n            height=150,\n            key=\"edit_src_config\",\n        )\n\n    st.divider()\n\n    # Info sur la source\n    col_info1, col_info2, col_info3 = st.columns(3)\n    with col_info1:\n        if source.last_check:\n            from src.utils.dates import format_relative\n            st.caption(f\"Dernier check : {format_relative(source.last_check)}\")\n        else:\n            st.caption(\"Dernier check : jamais\")\n    with col_info2:\n        st.caption(f\"Erreurs consÃ©cutives : {source.consecutive_errors}\")\n    with col_info3:\n        st.caption(f\"ID : {source.id[:8]}...\")\n\n    st.divider()\n\n    col1, col2 = st.columns(2)\n    with col1:\n        if st.button(\"ðŸ’¾ Sauvegarder\", use_container_width=True, type=\"primary\"):\n            if name and url:\n                try:\n                    import json as _json\n                    # Parse tags\n                    tags = [t.strip() for t in tags_str.split(\",\") if t.strip()] if tags_str else []\n\n                    # Parse config\n                    try:\n                        config = _json.loads(config_str) if config_str.strip() else {}\n                    except _json.JSONDecodeError:\n                        st.error(\"Configuration JSON invalide\")\n                        return\n\n                    success = _run_async(_update_source(\n                        source_id=source.id,\n                        name=name,\n                        url=url,\n                        category=category if category else None,\n                        interval_minutes=interval,\n                        priority=priority,\n                        enabled=enabled,\n                        tags=tags,\n                        config=config,\n                    ))\n\n                    if success:\n                        st.success(\"Source mise Ã  jour !\")\n                        st.rerun()\n                    else:\n                        st.error(\"Erreur lors de la mise Ã  jour\")\n                except Exception as e:\n                    st.error(f\"Erreur : {e}\")\n            else:\n                st.warning(\"Nom et URL requis\")\n    with col2:\n        if st.button(\"âŒ Annuler\", use_container_width=True):\n            st.rerun()\n\n\ndef render_sources_page() -> None:\n    \"\"\"Render the sources management page.\"\"\"\n    st.header(\"ðŸ“¡ Gestion des sources\")\n\n    # Load sources from database\n    sources = run_async(get_all_sources())\n\n    # Action buttons\n    col1, col2, col3, col4, col5 = st.columns([1, 1, 1.2, 1.2, 2])\n    with col1:\n        if st.button(\"âž• Ajouter\", use_container_width=True):\n            add_source_dialog()\n    with col2:\n        if st.button(\"ðŸ”„ Rafraichir\", use_container_width=True):\n            st.rerun()\n    with col3:\n        if st.button(\"ðŸ“¥ Collecter tout\", use_container_width=True, help=\"Lancer la collecte sur toutes les sources actives\"):\n            with st.spinner(\"Collecte en cours...\"):\n                result = run_async(run_collection_now())\n                if result[\"success\"]:\n                    st.success(result[\"message\"])\n                    if result.get(\"errors\"):\n                        for err in result[\"errors\"]:\n                            st.warning(err)\n                else:\n                    st.error(result[\"message\"])\n    with col4:\n        with st.popover(\"ðŸ“¤ OPML\", use_container_width=True):\n            st.markdown(\"**Import/Export OPML**\")\n            st.caption(\"Format standard pour echanger des flux RSS\")\n\n            # Export\n            st.markdown(\"---\")\n            st.markdown(\"**Exporter**\")\n            export_name = st.text_input(\"Nom du fichier\", value=\"sentinelpi_feeds\", key=\"opml_export_name\")\n            group_by_cat = st.checkbox(\"Grouper par categorie\", value=True, key=\"opml_group\")\n\n            if st.button(\"ðŸ“¥ Exporter OPML\", use_container_width=True, key=\"opml_export_btn\"):\n                from src.utils.opml import export_database_to_opml\n                from src.utils.config import PROJECT_ROOT\n                export_path = PROJECT_ROOT / \"data\" / f\"{export_name}.opml\"\n                result = run_async(export_database_to_opml(\n                    file_path=export_path,\n                    group_by_category=group_by_cat,\n                ))\n                if result[\"total\"] > 0:\n                    st.success(f\"Exporte {result['total']} sources vers {result['file_path']}\")\n                else:\n                    st.warning(\"Aucune source RSS a exporter\")\n\n            # Import\n            st.markdown(\"---\")\n            st.markdown(\"**Importer**\")\n            uploaded_file = st.file_uploader(\"Fichier OPML\", type=[\"opml\", \"xml\"], key=\"opml_upload\")\n            import_enabled = st.checkbox(\"Activer les sources importees\", value=True, key=\"opml_import_enabled\")\n            skip_dups = st.checkbox(\"Ignorer les doublons\", value=True, key=\"opml_skip_dups\")\n\n            if uploaded_file is not None:\n                if st.button(\"ðŸ“¤ Importer OPML\", use_container_width=True, key=\"opml_import_btn\"):\n                    import tempfile\n                    from src.utils.opml import import_opml_to_database\n\n                    # Save uploaded file temporarily\n                    with tempfile.NamedTemporaryFile(delete=False, suffix=\".opml\") as tmp:\n                        tmp.write(uploaded_file.getvalue())\n                        tmp_path = tmp.name\n\n                    try:\n                        result = run_async(import_opml_to_database(\n                            file_path=tmp_path,\n                            enabled=import_enabled,\n                            skip_duplicates=skip_dups,\n                        ))\n                        st.success(f\"Importe: {result['imported']} | Ignores: {result['skipped']}\")\n                        if result['errors']:\n                            for err in result['errors'][:5]:\n                                st.warning(err)\n                        st.rerun()\n                    except Exception as e:\n                        st.error(f\"Erreur: {e}\")\n                    finally:\n                        import os\n                        os.unlink(tmp_path)\n\n    st.divider()\n\n    if sources:\n        from src.dashboard.components.sources import (\n            get_source_type_icon, get_status_badge,\n            _run_async as _src_async, _toggle_source, _test_source, _delete_source,\n        )\n\n        # Table header\n        h_icon, h_name, h_url, h_int, h_cat, h_status, h_last, h_edit, h_tog, h_test, h_col, h_del = st.columns(\n            [0.35, 1.4, 1.8, 0.45, 0.55, 0.75, 0.75, 0.35, 0.35, 0.35, 0.55, 0.35]\n        )\n        with h_icon:\n            st.caption(\"**Type**\")\n        with h_name:\n            st.caption(\"**Nom**\")\n        with h_url:\n            st.caption(\"**URL**\")\n        with h_int:\n            st.caption(\"**Interv.**\")\n        with h_cat:\n            st.caption(\"**Cat.**\")\n        with h_status:\n            st.caption(\"**Statut**\")\n        with h_last:\n            st.caption(\"**Check**\")\n        with h_edit:\n            st.caption(\"**Edit**\")\n        with h_tog:\n            st.caption(\"**On/Off**\")\n        with h_test:\n            st.caption(\"**Test**\")\n        with h_col:\n            st.caption(\"**Collect**\")\n        with h_del:\n            st.caption(\"**Suppr**\")\n\n        # Render each source as a compact row with inline actions\n        for s in sources:\n            stype = s.type.value if hasattr(s.type, \"value\") else s.type\n            icon = get_source_type_icon(stype)\n            status = get_status_badge(s)\n            last = \"-\"\n            if s.last_check:\n                from src.utils.dates import format_relative\n                last = format_relative(s.last_check) if hasattr(s.last_check, \"timestamp\") else str(s.last_check)\n\n            c_icon, c_name, c_url, c_int, c_cat, c_status, c_last, c_edit, c_tog, c_test, c_col, c_del = st.columns(\n                [0.35, 1.4, 1.8, 0.45, 0.55, 0.75, 0.75, 0.35, 0.35, 0.35, 0.55, 0.35]\n            )\n            with c_icon:\n                st.markdown(icon)\n            with c_name:\n                st.markdown(f\"**{s.name}**\")\n            with c_url:\n                short_url = s.url[:30] + \"...\" if len(s.url) > 30 else s.url\n                st.caption(short_url)\n            with c_int:\n                st.caption(f\"{s.interval_minutes}m\")\n            with c_cat:\n                st.caption(s.category or \"-\")\n            with c_status:\n                st.caption(status)\n            with c_last:\n                st.caption(last)\n            with c_edit:\n                if st.button(\"âœï¸\", key=f\"edit_{s.id}\", help=\"Modifier\"):\n                    edit_source_dialog(s)\n            with c_tog:\n                label = \"â–¶ï¸\" if not s.enabled else \"â¸ï¸\"\n                if st.button(label, key=f\"tog_{s.id}\", help=\"Activer/Pause\"):\n                    _src_async(_toggle_source(s.id, s.enabled))\n                    st.rerun()\n            with c_test:\n                if st.button(\"ðŸ”„\", key=f\"tst_{s.id}\", help=\"Tester\"):\n                    with st.spinner(\"...\"):\n                        success, msg = _src_async(_test_source(s.id))\n                        if success:\n                            st.toast(f\"âœ… {s.name}: {msg}\")\n                        else:\n                            st.toast(f\"âŒ {s.name}: {msg}\")\n            with c_col:\n                if st.button(\"ðŸ“¥\", key=f\"col_{s.id}\", help=\"Collecter maintenant\"):\n                    with st.spinner(\"...\"):\n                        result = run_async(run_collection_now(s.id))\n                        if result[\"success\"]:\n                            st.toast(result[\"message\"])\n                        else:\n                            st.error(result[\"message\"])\n            with c_del:\n                # Use popover for delete confirmation\n                with st.popover(\"ðŸ—‘\", help=\"Supprimer\"):\n                    st.warning(f\"Supprimer **{s.name}** ?\")\n                    st.caption(\"Cette action supprimera aussi tous les items collectes.\")\n                    if st.button(\"Confirmer\", key=f\"confirm_del_{s.id}\", type=\"primary\"):\n                        if _src_async(_delete_source(s.id)):\n                            st.toast(f\"Source '{s.name}' supprimee\")\n                            st.rerun()\n                        else:\n                            st.error(\"Erreur lors de la suppression\")\n    else:\n        st.info(\"Aucune source configuree.\")\n\n\ndef _render_condition_editor(prefix: str, cond_type: str = \"keywords\", field: str = \"all\",\n                             operator: str = \"contains\", value_text: str = \"\",\n                             case_sensitive: bool = False, logic: str = \"and\",\n                             sub_cond_text: str = \"\"):\n    \"\"\"Shared condition editor UI. Returns a conditions dict.\"\"\"\n    ct = st.selectbox(\"Type de condition\", options=[\"keywords\", \"regex\", \"compound\"],\n        index=[\"keywords\", \"regex\", \"compound\"].index(cond_type), key=f\"{prefix}_ctype\")\n    cf = st.selectbox(\"Champ\", options=[\"all\", \"title\", \"content\", \"author\", \"url\"],\n        index=[\"all\", \"title\", \"content\", \"author\", \"url\"].index(field), key=f\"{prefix}_field\")\n\n    if ct == \"keywords\":\n        op = st.selectbox(\"Operateur\", options=[\"contains\", \"not_contains\", \"starts_with\", \"ends_with\", \"equals\"],\n            index=[\"contains\", \"not_contains\", \"starts_with\", \"ends_with\", \"equals\"].index(operator) if operator in [\"contains\", \"not_contains\", \"starts_with\", \"ends_with\", \"equals\"] else 0,\n            key=f\"{prefix}_op\")\n        val = st.text_area(\"Mots-cles (un par ligne ou virgules)\", value=value_text, height=100, key=f\"{prefix}_kw\")\n        cs = st.checkbox(\"Sensible a la casse\", value=case_sensitive, key=f\"{prefix}_cs\")\n        kw_list = [k.strip() for line in val.split(\"\\n\") for k in line.split(\",\") if k.strip()]\n        return {\"type\": \"keywords\", \"field\": cf, \"operator\": op, \"case_sensitive\": cs, \"value\": kw_list}, val\n    elif ct == \"regex\":\n        pattern = st.text_input(\"Expression reguliere\", value=value_text, key=f\"{prefix}_regex\")\n        cs = st.checkbox(\"Sensible a la casse\", value=case_sensitive, key=f\"{prefix}_cs\")\n        return {\"type\": \"regex\", \"field\": cf, \"operator\": \"matches\", \"case_sensitive\": cs, \"value\": pattern}, pattern\n    else:  # compound\n        lg = st.selectbox(\"Logique\", options=[\"and\", \"or\"],\n            index=[\"and\", \"or\"].index(logic), key=f\"{prefix}_logic\")\n        st.caption(\"Sous-conditions au format JSON (liste)\")\n        sub = st.text_area(\"Sous-conditions\", value=sub_cond_text,\n            placeholder='[{\"type\":\"keywords\",\"field\":\"title\",\"operator\":\"contains\",\"value\":[\"mot1\"]},\\n {\"type\":\"regex\",\"field\":\"content\",\"operator\":\"matches\",\"value\":\"pattern\"}]',\n            height=120, key=f\"{prefix}_sub\")\n        import json as _json\n        try:\n            sub_list = _json.loads(sub) if sub.strip() else []\n        except _json.JSONDecodeError:\n            sub_list = []\n            st.warning(\"JSON invalide pour les sous-conditions\")\n        return {\"type\": \"compound\", \"logic\": lg, \"conditions\": sub_list}, sub\n\n\n@st.dialog(\"Nouveau filtre\")\ndef add_filter_dialog():\n    \"\"\"Dialog for adding a new filter.\"\"\"\n    col1, col2 = st.columns(2)\n    with col1:\n        nf_name = st.text_input(\"Nom\", placeholder=\"Mon filtre\")\n        nf_desc = st.text_input(\"Description\", placeholder=\"Ce filtre...\")\n        nf_action = st.selectbox(\"Action\", options=[\"alert\", \"highlight\", \"tag\", \"exclude\", \"include\"])\n    with col2:\n        nf_score = st.number_input(\"Modificateur score\", value=0, step=5)\n        nf_priority = st.number_input(\"Priorite\", value=50, min_value=1)\n\n    st.divider()\n\n    # Targeting\n    with st.expander(\"Ciblage (optionnel)\"):\n        nf_categories = st.text_input(\"Categories (virgules)\", placeholder=\"tech, presse\", key=\"nf_cats\")\n        nf_source_ids = st.text_input(\"IDs sources (virgules)\", placeholder=\"id1, id2\", key=\"nf_sids\")\n\n    # Condition editor\n    st.subheader(\"Condition\")\n    new_cond, _ = _render_condition_editor(\"nf\")\n\n    # Action params\n    nf_ap = {}\n    if nf_action == \"alert\":\n        nf_severity = st.selectbox(\"Severite alerte\", options=[\"info\", \"notice\", \"warning\", \"critical\"], index=1)\n        nf_ap[\"severity\"] = nf_severity\n    elif nf_action == \"tag\":\n        nf_tag = st.text_input(\"Nom du tag\", placeholder=\"mon-tag\")\n        nf_ap[\"tag\"] = nf_tag\n\n    c1, c2 = st.columns(2)\n    with c1:\n        if st.button(\"ðŸ’¾ Enregistrer\", use_container_width=True):\n            has_value = bool(new_cond.get(\"value\")) or bool(new_cond.get(\"conditions\"))\n            if nf_name and has_value:\n                from src.storage.models import Filter, FilterAction\n                flt = Filter()\n                flt.id = hashlib.sha256(nf_name.encode()).hexdigest()[:32]\n                flt.name = nf_name\n                flt.description = nf_desc or None\n                flt.action = FilterAction(nf_action)\n                flt.action_params = nf_ap\n                flt.conditions = new_cond\n                flt.score_modifier = nf_score\n                flt.priority = nf_priority\n                flt.enabled = True\n                # Targeting\n                cats = [c.strip() for c in nf_categories.split(\",\") if c.strip()] if nf_categories else None\n                sids = [s.strip() for s in nf_source_ids.split(\",\") if s.strip()] if nf_source_ids else None\n                if cats:\n                    flt.categories = cats\n                if sids:\n                    flt.source_ids = sids\n\n                run_async(add_to_db(flt))\n                st.rerun()\n            else:\n                st.warning(\"Nom et au moins une condition requis\")\n    with c2:\n        if st.button(\"âŒ Annuler\", use_container_width=True):\n            st.rerun()\n\n\n@st.dialog(\"Modifier le filtre\")\ndef edit_filter_dialog(filter_obj):\n    \"\"\"Dialog for editing an existing filter.\"\"\"\n    import json as _json\n    action_val = filter_obj.action.value if hasattr(filter_obj.action, \"value\") else filter_obj.action\n    cond = filter_obj.conditions or {}\n    cond_type = cond.get(\"type\", \"keywords\")\n    cond_field = cond.get(\"field\", \"all\")\n    cond_operator = cond.get(\"operator\", \"contains\")\n    cond_cs = cond.get(\"case_sensitive\", False)\n    cond_value = cond.get(\"value\", [])\n    cond_logic = cond.get(\"logic\", \"and\")\n\n    # Prepare value text based on condition type\n    if cond_type == \"keywords\" and isinstance(cond_value, list):\n        value_text = \"\\n\".join(cond_value)\n    elif cond_type == \"regex\":\n        value_text = str(cond_value)\n    elif cond_type == \"compound\":\n        value_text = \"\"\n    else:\n        value_text = str(cond_value) if cond_value else \"\"\n\n    sub_cond_text = \"\"\n    if cond_type == \"compound\":\n        sub_cond_text = _json.dumps(cond.get(\"conditions\", []), indent=2, ensure_ascii=False)\n\n    col1, col2 = st.columns(2)\n    with col1:\n        ef_name = st.text_input(\"Nom\", value=filter_obj.name)\n        ef_desc = st.text_input(\"Description\", value=filter_obj.description or \"\")\n        ef_action = st.selectbox(\n            \"Action\",\n            options=[\"alert\", \"highlight\", \"tag\", \"exclude\", \"include\"],\n            index=[\"alert\", \"highlight\", \"tag\", \"exclude\", \"include\"].index(action_val) if action_val in [\"alert\", \"highlight\", \"tag\", \"exclude\", \"include\"] else 0,\n        )\n    with col2:\n        ef_score = st.number_input(\"Modificateur score\", value=int(filter_obj.score_modifier), step=5)\n        ef_priority = st.number_input(\"Priorite\", value=filter_obj.priority, min_value=1)\n        ef_enabled = st.checkbox(\"Actif\", value=filter_obj.enabled)\n\n    st.divider()\n\n    # Targeting\n    with st.expander(\"Ciblage (optionnel)\"):\n        existing_cats = \", \".join(filter_obj.categories) if filter_obj.categories else \"\"\n        existing_sids = \", \".join(filter_obj.source_ids) if filter_obj.source_ids else \"\"\n        ef_categories = st.text_input(\"Categories (virgules)\", value=existing_cats, key=\"ef_cats\")\n        ef_source_ids = st.text_input(\"IDs sources (virgules)\", value=existing_sids, key=\"ef_sids\")\n\n    # Condition editor\n    st.subheader(\"Condition\")\n    new_cond, _ = _render_condition_editor(\"ef\", cond_type, cond_field, cond_operator,\n                                            value_text, cond_cs, cond_logic, sub_cond_text)\n\n    # Action params\n    ap = filter_obj.action_params or {}\n    ef_severity = None\n    ef_tag = None\n    if ef_action == \"alert\":\n        ef_severity = st.selectbox(\"Severite alerte\", options=[\"info\", \"notice\", \"warning\", \"critical\"],\n            index=[\"info\", \"notice\", \"warning\", \"critical\"].index(ap.get(\"severity\", \"notice\")))\n    elif ef_action == \"tag\":\n        ef_tag = st.text_input(\"Tag\", value=ap.get(\"tag\", \"\"))\n\n    c1, c2 = st.columns(2)\n    with c1:\n        if st.button(\"ðŸ’¾ Sauvegarder\", use_container_width=True):\n            new_ap = {}\n            if ef_action == \"alert\" and ef_severity:\n                new_ap[\"severity\"] = ef_severity\n            elif ef_action == \"tag\" and ef_tag:\n                new_ap[\"tag\"] = ef_tag\n\n            # Targeting\n            cats = [c.strip() for c in ef_categories.split(\",\") if c.strip()] if ef_categories else None\n            sids = [s.strip() for s in ef_source_ids.split(\",\") if s.strip()] if ef_source_ids else None\n\n            run_async(_update_filter_db(\n                filter_obj.id, ef_name, ef_desc, ef_action,\n                new_ap, new_cond, ef_score, ef_priority, ef_enabled\n            ))\n            # Update targeting separately\n            async def _update_targeting():\n                from src.storage.database import get_session\n                from src.storage.models import Filter\n                from sqlalchemy import select\n                async with get_session() as session:\n                    result = await session.execute(select(Filter).where(Filter.id == filter_obj.id))\n                    f = result.scalar_one_or_none()\n                    if f:\n                        f.categories = cats\n                        f.source_ids = sids\n                        await session.commit()\n            run_async(_update_targeting())\n            st.rerun()\n    with c2:\n        if st.button(\"âŒ Annuler\", use_container_width=True):\n            st.rerun()\n\n\ndef render_filters_page() -> None:\n    \"\"\"Render the filters configuration page.\"\"\"\n    st.header(\"ðŸŽ¯ Configuration des filtres\")\n\n    # Load filters from database\n    filters = run_async(get_all_filters())\n\n    col1, col2 = st.columns([1, 5])\n    with col1:\n        if st.button(\"âž• Nouveau filtre\", use_container_width=True):\n            add_filter_dialog()\n\n    st.divider()\n\n    if filters:\n        from src.dashboard.components.filters import (\n            get_action_badge, _format_conditions_summary,\n            _run_async as _flt_async, _toggle_filter, _delete_filter,\n        )\n\n        # Table header\n        h_st, h_name, h_act, h_cond, h_score, h_pri, h_edit, h_tog, h_del = st.columns(\n            [0.3, 1.8, 1, 2.8, 0.5, 0.5, 0.4, 0.4, 0.4]\n        )\n        with h_st:\n            st.caption(\"**On**\")\n        with h_name:\n            st.caption(\"**Nom**\")\n        with h_act:\n            st.caption(\"**Action**\")\n        with h_cond:\n            st.caption(\"**Conditions**\")\n        with h_score:\n            st.caption(\"**Score**\")\n        with h_pri:\n            st.caption(\"**Prio**\")\n        with h_edit:\n            st.caption(\"**Edit**\")\n        with h_tog:\n            st.caption(\"**On/Off**\")\n        with h_del:\n            st.caption(\"**Suppr**\")\n\n        for f in filters:\n            action_val = f.action.value if hasattr(f.action, \"value\") else f.action\n            badge = get_action_badge(action_val)\n            cond_summary = _format_conditions_summary(f.conditions or {})\n            score_str = f\"{f.score_modifier:+}\" if f.score_modifier else \"0\"\n            status_icon = \"âœ…\" if f.enabled else \"â¸ï¸\"\n\n            c_st, c_name, c_act, c_cond, c_score, c_pri, c_edit, c_tog, c_del = st.columns(\n                [0.3, 1.8, 1, 2.8, 0.5, 0.5, 0.4, 0.4, 0.4]\n            )\n            with c_st:\n                st.markdown(status_icon)\n            with c_name:\n                st.markdown(f\"**{f.name}**\")\n                if f.description:\n                    st.caption(f.description[:50])\n            with c_act:\n                st.caption(badge)\n            with c_cond:\n                if cond_summary:\n                    st.caption(cond_summary[:70])\n            with c_score:\n                st.caption(score_str)\n            with c_pri:\n                st.caption(str(f.priority))\n            with c_edit:\n                if st.button(\"âœï¸\", key=f\"fedit_{f.id}\", help=\"Modifier\"):\n                    edit_filter_dialog(f)\n            with c_tog:\n                label = \"â–¶ï¸\" if not f.enabled else \"â¸ï¸\"\n                if st.button(label, key=f\"ftog_{f.id}\", help=\"Activer/Pause\"):\n                    _flt_async(_toggle_filter(f.id, f.enabled))\n                    st.rerun()\n            with c_del:\n                if st.button(\"ðŸ—‘\", key=f\"fdel_{f.id}\", help=\"Supprimer\"):\n                    _flt_async(_delete_filter(f.id))\n                    st.rerun()\n\n    else:\n        st.info(\"Aucun filtre configure.\")\n\n\ndef render_alerts_page() -> None:\n    \"\"\"Render the alerts history page.\"\"\"\n    st.header(\"ðŸ”” Historique des alertes\")\n\n    # Filters\n    col1, col2, col3 = st.columns([2, 2, 2])\n\n    with col1:\n        severity = st.selectbox(\n            \"SÃ©vÃ©ritÃ©\",\n            options=[\"all\", \"critical\", \"warning\", \"notice\", \"info\"],\n            format_func=lambda x: {\n                \"all\": \"Toutes\",\n                \"critical\": \"ðŸš¨ Critique\",\n                \"warning\": \"âš ï¸ Attention\",\n                \"notice\": \"ðŸ“¢ Notice\",\n                \"info\": \"â„¹ï¸ Info\",\n            }.get(x, x),\n        )\n\n    with col2:\n        date_range = st.selectbox(\n            \"PÃ©riode\",\n            options=[\"today\", \"week\", \"month\", \"all\"],\n            format_func=lambda x: {\n                \"today\": \"Aujourd'hui\",\n                \"week\": \"Cette semaine\",\n                \"month\": \"Ce mois\",\n                \"all\": \"Tout\",\n            }.get(x, x),\n        )\n\n    with col3:\n        if st.button(\"ðŸ”„ Actualiser\", use_container_width=True):\n            st.rerun()\n\n    st.divider()\n\n    # Load alerts\n    alerts = run_async(get_all_alerts(\n        severity_filter=severity if severity != \"all\" else None,\n        date_filter=date_range if date_range != \"all\" else None,\n    ))\n\n    if alerts:\n        st.caption(f\"{len(alerts)} alertes\")\n        from src.dashboard.components.alerts import render_alert_card\n        for alert in alerts:\n            render_alert_card(alert, show_actions=True)\n    else:\n        st.info(\"ðŸ“­ Aucune alerte enregistrÃ©e.\", icon=\"â„¹ï¸\")\n\n\ndef _stat_card(label: str, value: str, icon: str, color: str = \"#4f8bf9\") -> str:\n    \"\"\"Generate HTML for a styled stat card.\"\"\"\n    return (\n        f'<div style=\"background:linear-gradient(135deg,{color}22,{color}08);'\n        f'border-left:3px solid {color};border-radius:8px;padding:1rem 1.2rem;'\n        f'margin-bottom:0.5rem;\">'\n        f'<div style=\"font-size:0.78rem;opacity:0.7;margin-bottom:0.2rem;\">{icon} {label}</div>'\n        f'<div style=\"font-size:1.6rem;font-weight:700;color:{color};\">{value}</div>'\n        f'</div>'\n    )\n\n\ndef render_stats_page() -> None:\n    \"\"\"Render the statistics page.\"\"\"\n    import plotly.graph_objects as go\n\n    # Tab selector for basic vs advanced stats\n    stats_mode = st.radio(\n        \"Mode\",\n        options=[\"basic\", \"advanced\"],\n        format_func=lambda x: {\"basic\": \"ðŸ“Š Statistiques\", \"advanced\": \"ðŸ“ˆ Avancees\"}.get(x, x),\n        horizontal=True,\n        label_visibility=\"collapsed\",\n    )\n\n    if stats_mode == \"advanced\":\n        # Render advanced statistics page\n        from src.dashboard.components.statistics import render_statistics_page\n        render_statistics_page(run_async)\n        return\n\n    st.header(\"ðŸ“Š Statistiques\")\n\n    # Period selector\n    period = st.radio(\n        \"Periode\",\n        options=[\"week\", \"month\", \"quarter\"],\n        format_func=lambda x: {\"week\": \"7 jours\", \"month\": \"30 jours\", \"quarter\": \"90 jours\"}.get(x, x),\n        horizontal=True,\n        label_visibility=\"collapsed\",\n    )\n\n    stats = run_async(get_stats(period))\n\n    # Metric cards row\n    c1, c2, c3, c4 = st.columns(4)\n    with c1:\n        st.markdown(_stat_card(\"Items collectes\", f\"{stats['items_count']:,}\", \"ðŸ“°\", \"#4f8bf9\"), unsafe_allow_html=True)\n    with c2:\n        st.markdown(_stat_card(\"Non lus\", str(stats[\"unread_count\"]), \"ðŸ“­\", \"#f59e0b\"), unsafe_allow_html=True)\n    with c3:\n        st.markdown(_stat_card(\"Alertes\", str(stats[\"alerts_count\"]), \"ðŸ””\", \"#ef4444\"), unsafe_allow_html=True)\n    with c4:\n        health_txt = f\"{stats['sources_healthy']} OK\"\n        if stats[\"sources_error\"] > 0:\n            health_txt += f\" Â· {stats['sources_error']} err\"\n        st.markdown(_stat_card(\"Sources\", health_txt, \"ðŸ“¡\", \"#10b981\"), unsafe_allow_html=True)\n\n    st.markdown(\"\")\n\n    palette = [\"#4f8bf9\", \"#10b981\", \"#f59e0b\", \"#ef4444\", \"#8b5cf6\",\n               \"#ec4899\", \"#06b6d4\", \"#84cc16\", \"#f97316\", \"#6366f1\"]\n\n    # Two columns: pie charts + word cloud / top items\n    col_left, col_right = st.columns(2)\n\n    with col_left:\n        # Donut chart: items by source\n        st.markdown(\"**Repartition par source**\")\n        if stats[\"items_by_source\"]:\n            labels = [row[0] for row in stats[\"items_by_source\"]]\n            values = [row[1] for row in stats[\"items_by_source\"]]\n            fig = go.Figure(data=[go.Pie(\n                labels=labels, values=values,\n                hole=0.45,\n                marker=dict(colors=palette[:len(labels)]),\n                textinfo=\"label+percent\",\n                textposition=\"outside\",\n                textfont_size=11,\n                hoverinfo=\"label+value+percent\",\n            )])\n            fig.update_layout(\n                showlegend=False,\n                margin=dict(t=10, b=10, l=10, r=10),\n                height=280,\n                paper_bgcolor=\"rgba(0,0,0,0)\",\n                plot_bgcolor=\"rgba(0,0,0,0)\",\n            )\n            st.plotly_chart(fig, use_container_width=True)\n        else:\n            st.caption(\"Aucune donnee.\")\n\n        # Donut chart: items by category\n        st.markdown(\"**Repartition par categorie**\")\n        if stats[\"items_by_category\"]:\n            cat_labels = [row[0] or \"Sans categorie\" for row in stats[\"items_by_category\"]]\n            cat_values = [row[1] for row in stats[\"items_by_category\"]]\n            fig2 = go.Figure(data=[go.Pie(\n                labels=cat_labels, values=cat_values,\n                hole=0.45,\n                marker=dict(colors=palette[2:2 + len(cat_labels)]),\n                textinfo=\"label+percent\",\n                textposition=\"outside\",\n                textfont_size=11,\n                hoverinfo=\"label+value+percent\",\n            )])\n            fig2.update_layout(\n                showlegend=False,\n                margin=dict(t=10, b=10, l=10, r=10),\n                height=250,\n                paper_bgcolor=\"rgba(0,0,0,0)\",\n                plot_bgcolor=\"rgba(0,0,0,0)\",\n            )\n            st.plotly_chart(fig2, use_container_width=True)\n        else:\n            st.caption(\"Aucune donnee.\")\n\n        # Donut chart: alerts by severity\n        st.markdown(\"**Alertes par severite**\")\n        severity_data = stats[\"alerts_by_severity\"]\n        if any(v > 0 for v in severity_data.values()):\n            sev_labels = [k.capitalize() for k, v in severity_data.items() if v > 0]\n            sev_values = [v for v in severity_data.values() if v > 0]\n            sev_colors = {\"Critical\": \"#ef4444\", \"Warning\": \"#f59e0b\", \"Notice\": \"#4f8bf9\", \"Info\": \"#9ca3af\"}\n            sev_c = [sev_colors.get(l, \"#ccc\") for l in sev_labels]\n            fig3 = go.Figure(data=[go.Pie(\n                labels=sev_labels, values=sev_values,\n                hole=0.45,\n                marker=dict(colors=sev_c),\n                textinfo=\"label+value\",\n                textposition=\"inside\",\n                textfont_size=12,\n                hoverinfo=\"label+value+percent\",\n            )])\n            fig3.update_layout(\n                showlegend=False,\n                margin=dict(t=10, b=10, l=10, r=10),\n                height=220,\n                paper_bgcolor=\"rgba(0,0,0,0)\",\n                plot_bgcolor=\"rgba(0,0,0,0)\",\n            )\n            st.plotly_chart(fig3, use_container_width=True)\n        else:\n            st.caption(\"Aucune alerte.\")\n\n    with col_right:\n        # Word cloud (HTML-based)\n        st.markdown(\"**Nuage de mots-cles**\")\n        if stats[\"top_keywords\"]:\n            max_count = stats[\"top_keywords\"][0][1] if stats[\"top_keywords\"] else 1\n            min_size = 0.8\n            max_size = 2.8\n            cloud_html = '<div style=\"text-align:center;line-height:2.4;padding:1rem 0.5rem;\">'\n            for i, (word, count) in enumerate(stats[\"top_keywords\"][:20]):\n                ratio = count / max_count if max_count > 0 else 0\n                size = min_size + (max_size - min_size) * ratio\n                color = palette[i % len(palette)]\n                weight = 400 + int(400 * ratio)\n                cloud_html += (\n                    f'<span style=\"display:inline-block;margin:4px 8px;'\n                    f'font-size:{size:.2f}rem;font-weight:{weight};'\n                    f'color:{color};cursor:default;\" '\n                    f'title=\"{word}: {count} occurrences\">'\n                    f'{word}</span>'\n                )\n            cloud_html += '</div>'\n            st.markdown(cloud_html, unsafe_allow_html=True)\n        else:\n            st.caption(\"Aucun mot-cle.\")\n\n        st.markdown(\"\")\n\n        # Top articles\n        st.markdown(\"**Top articles**\")\n        if stats[\"top_items\"]:\n            for i, (item, source_name) in enumerate(stats[\"top_items\"][:8], 1):\n                score = item.relevance_score\n                bar_color = \"#10b981\" if score > 70 else \"#f59e0b\" if score > 40 else \"#9ca3af\"\n                title = item.title[:55] + \"...\" if len(item.title) > 55 else item.title\n                st.markdown(\n                    f'<div style=\"display:flex;align-items:center;gap:8px;margin-bottom:6px;\">'\n                    f'<span style=\"background:{bar_color};color:#fff;padding:1px 6px;'\n                    f'border-radius:4px;font-size:0.75rem;font-weight:600;min-width:28px;'\n                    f'text-align:center;\">{score:.0f}</span>'\n                    f'<span style=\"font-size:0.85rem;line-height:1.3;\">{i}. {title}</span>'\n                    f'</div>',\n                    unsafe_allow_html=True,\n                )\n                st.caption(f\"   {source_name}\")\n        else:\n            st.caption(\"Aucun item.\")\n\n    # Footer: system info\n    st.markdown(\"\")\n    fc1, fc2, fc3 = st.columns(3)\n    with fc1:\n        if stats[\"last_collection\"]:\n            from src.utils.dates import format_relative\n            st.caption(f\"Derniere collecte : {format_relative(stats['last_collection'])}\")\n        else:\n            st.caption(\"Aucune collecte\")\n    with fc2:\n        st.caption(f\"Base : {stats['db_size_mb']:.1f} MB\")\n    with fc3:\n        st.caption(f\"{stats['sources_count']} source(s) active(s)\")\n\n\ndef _save_settings_yaml(data: dict) -> None:\n    \"\"\"Save settings dict to YAML file.\"\"\"\n    import yaml\n    from src.utils.config import PROJECT_ROOT\n    settings_path = PROJECT_ROOT / \"config\" / \"settings.yaml\"\n    with open(settings_path, \"w\", encoding=\"utf-8\") as f:\n        yaml.dump(data, f, default_flow_style=False, allow_unicode=True, sort_keys=False)\n\n\ndef _load_settings_yaml() -> dict:\n    \"\"\"Load raw settings dict from YAML.\"\"\"\n    import yaml\n    from src.utils.config import PROJECT_ROOT\n    settings_path = PROJECT_ROOT / \"config\" / \"settings.yaml\"\n    with open(settings_path, \"r\", encoding=\"utf-8\") as f:\n        return yaml.safe_load(f)\n\n\ndef _load_alerts_yaml() -> dict:\n    \"\"\"Load raw alerts config dict from YAML.\"\"\"\n    import yaml\n    from src.utils.config import PROJECT_ROOT\n    alerts_path = PROJECT_ROOT / \"config\" / \"alerts.yaml\"\n    try:\n        with open(alerts_path, \"r\", encoding=\"utf-8\") as f:\n            return yaml.safe_load(f) or {}\n    except FileNotFoundError:\n        return {}\n\n\ndef _save_alerts_yaml(data: dict) -> None:\n    \"\"\"Save alerts config dict to YAML file.\"\"\"\n    import yaml\n    from src.utils.config import PROJECT_ROOT\n    alerts_path = PROJECT_ROOT / \"config\" / \"alerts.yaml\"\n    with open(alerts_path, \"w\", encoding=\"utf-8\") as f:\n        yaml.dump(data, f, default_flow_style=False, allow_unicode=True, sort_keys=False)\n\n\ndef render_settings_page() -> None:\n    \"\"\"Render the settings page with editable fields.\"\"\"\n    st.header(\"âš™ï¸ Parametres\")\n\n    raw = _load_settings_yaml()\n\n    tabs = st.tabs([\"ðŸ”§ General\", \"ðŸ“¡ Collecte\", \"ðŸ”” Alertes\", \"ðŸ—„ï¸ Base de donnees\", \"ðŸ“‹ Logs\", \"ðŸ›  Maintenance\", \"ðŸ”’ Securite\"])\n\n    with tabs[0]:\n        with st.form(\"settings_general\"):\n            col1, col2 = st.columns(2)\n            with col1:\n                app_name = st.text_input(\"Nom\", value=raw.get(\"app\", {}).get(\"name\", \"SentinelPi\"))\n                app_tz = st.text_input(\"Fuseau horaire\", value=raw.get(\"app\", {}).get(\"timezone\", \"Europe/Paris\"))\n            with col2:\n                app_version = st.text_input(\"Version\", value=raw.get(\"app\", {}).get(\"version\", \"1.0.0\"))\n                log_level = st.selectbox(\n                    \"Niveau de log\",\n                    options=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"],\n                    index=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"].index(\n                        raw.get(\"logging\", {}).get(\"level\", \"INFO\")\n                    ),\n                )\n            if st.form_submit_button(\"ðŸ’¾ Sauvegarder General\", use_container_width=True):\n                new_config = dict(raw)\n                new_config[\"app\"] = {\"name\": app_name, \"version\": app_version, \"timezone\": app_tz}\n                new_config.setdefault(\"logging\", {})[\"level\"] = log_level\n                try:\n                    _save_settings_yaml(new_config)\n                    st.success(\"Parametres generaux sauvegardes !\")\n                except Exception as e:\n                    st.error(f\"Erreur: {e}\")\n\n    with tabs[1]:\n        with st.form(\"settings_collection\"):\n            col1, col2 = st.columns(2)\n            coll = raw.get(\"collection\", {})\n            with col1:\n                coll_interval = st.number_input(\"Intervalle par defaut (min)\", value=coll.get(\"default_interval_minutes\", 60), min_value=5)\n                coll_concurrent = st.number_input(\"Collecteurs simultanes\", value=coll.get(\"max_concurrent_collectors\", 3), min_value=1, max_value=10)\n                coll_timeout = st.number_input(\"Timeout collecteur (s)\", value=coll.get(\"collector_timeout\", 120), min_value=10)\n            with col2:\n                coll_max_items = st.number_input(\"Items max par source\", value=coll.get(\"max_items_per_source\", 100), min_value=10)\n                coll_dedup = st.number_input(\"Fenetre dedup (jours)\", value=coll.get(\"dedup_window_days\", 30), min_value=1)\n\n            st.divider()\n            http = raw.get(\"http\", {})\n            col1, col2 = st.columns(2)\n            with col1:\n                http_timeout = st.number_input(\"HTTP timeout (s)\", value=http.get(\"timeout\", 30), min_value=5)\n                http_retries = st.number_input(\"HTTP retries\", value=http.get(\"max_retries\", 3), min_value=0)\n            with col2:\n                http_rate = st.number_input(\"Rate limit (req/s)\", value=http.get(\"rate_limit\", 2), min_value=1)\n                http_ua = st.text_input(\"User-Agent\", value=http.get(\"user_agent\", \"\"))\n\n            st.divider()\n            st.subheader(\"Scheduler\")\n            sched = raw.get(\"scheduler\", {})\n            col1, col2 = st.columns(2)\n            with col1:\n                sched_enabled = st.checkbox(\"Scheduler actif\", value=sched.get(\"enabled\", True))\n                daily_time = st.text_input(\"Rapport quotidien (HH:MM)\", value=sched.get(\"daily_report_time\", \"08:00\"))\n            with col2:\n                weekly_day = st.number_input(\"Jour rapport hebdo (0=lun)\", value=sched.get(\"weekly_report_day\", 0), min_value=0, max_value=6)\n                weekly_time = st.text_input(\"Heure rapport hebdo\", value=sched.get(\"weekly_report_time\", \"09:00\"))\n\n            if st.form_submit_button(\"ðŸ’¾ Sauvegarder Collecte\", use_container_width=True):\n                new_config = dict(raw)\n                new_config[\"collection\"] = {\n                    \"default_interval_minutes\": coll_interval,\n                    \"max_concurrent_collectors\": coll_concurrent,\n                    \"max_items_per_source\": coll_max_items,\n                    \"dedup_window_days\": coll_dedup,\n                    \"collector_timeout\": coll_timeout,\n                }\n                new_config[\"http\"] = {\n                    \"timeout\": http_timeout, \"max_retries\": http_retries,\n                    \"retry_delay\": raw.get(\"http\", {}).get(\"retry_delay\", 5),\n                    \"user_agent\": http_ua, \"rate_limit\": http_rate,\n                    \"cache\": raw.get(\"http\", {}).get(\"cache\", {}),\n                }\n                new_config[\"scheduler\"] = {\n                    \"enabled\": sched_enabled,\n                    \"check_interval_seconds\": sched.get(\"check_interval_seconds\", 60),\n                    \"daily_report_time\": daily_time,\n                    \"weekly_report_day\": weekly_day,\n                    \"weekly_report_time\": weekly_time,\n                }\n                try:\n                    _save_settings_yaml(new_config)\n                    st.success(\"Parametres de collecte sauvegardes !\")\n                except Exception as e:\n                    st.error(f\"Erreur: {e}\")\n\n    with tabs[2]:\n        import json as _json\n        alerts_raw = _load_alerts_yaml()\n        alerting = alerts_raw.get(\"alerting\", {})\n\n        with st.form(\"settings_alerts\"):\n            # General\n            st.subheader(\"General\")\n            alert_enabled = st.checkbox(\"Alertes activees\", value=alerting.get(\"enabled\", True))\n\n            st.divider()\n\n            # Aggregation\n            st.subheader(\"Agregation\")\n            agg = alerting.get(\"aggregation\", {})\n            agg_enabled = st.checkbox(\"Agregation activee\", value=agg.get(\"enabled\", True))\n            col1, col2 = st.columns(2)\n            with col1:\n                agg_window = st.number_input(\"Fenetre (minutes)\", value=agg.get(\"window_minutes\", 15), min_value=1)\n            with col2:\n                agg_max = st.number_input(\"Max alertes par fenetre\", value=agg.get(\"max_alerts_per_window\", 10), min_value=1)\n\n            st.divider()\n\n            # Quiet hours\n            st.subheader(\"Heures silencieuses\")\n            qh = alerting.get(\"quiet_hours\", {})\n            qh_enabled = st.checkbox(\"Heures silencieuses activees\", value=qh.get(\"enabled\", False))\n            col1, col2, col3 = st.columns(3)\n            with col1:\n                qh_start = st.text_input(\"Debut (HH:MM)\", value=qh.get(\"start\", \"22:00\"))\n            with col2:\n                qh_end = st.text_input(\"Fin (HH:MM)\", value=qh.get(\"end\", \"07:00\"))\n            with col3:\n                qh_bypass = st.checkbox(\"Critical bypass\", value=qh.get(\"bypass_for_critical\", True))\n\n            st.divider()\n\n            # Channels\n            st.subheader(\"Canaux de notification\")\n            channels = alerting.get(\"channels\", {})\n\n            # Telegram\n            with st.expander(\"ðŸ“± Telegram\"):\n                tg = channels.get(\"telegram\", {})\n                tg_enabled = st.checkbox(\"Telegram actif\", value=tg.get(\"enabled\", False), key=\"tg_enabled\")\n                col1, col2 = st.columns(2)\n                with col1:\n                    tg_token = st.text_input(\"Bot Token\", value=tg.get(\"bot_token\", \"\"), key=\"tg_token\")\n                    tg_severity = st.selectbox(\"Severite min.\", options=[\"info\", \"notice\", \"warning\", \"critical\"],\n                        index=[\"info\", \"notice\", \"warning\", \"critical\"].index(tg.get(\"min_severity\", \"notice\")),\n                        key=\"tg_severity\")\n                with col2:\n                    tg_chat = st.text_input(\"Chat ID\", value=tg.get(\"chat_id\", \"\"), key=\"tg_chat\")\n                    tg_silent = st.checkbox(\"Mode silencieux\", value=tg.get(\"silent\", False), key=\"tg_silent\")\n                tg_preview = st.checkbox(\"Desactiver apercu liens\", value=tg.get(\"disable_web_preview\", False), key=\"tg_preview\")\n\n            # Email\n            with st.expander(\"ðŸ“§ Email\"):\n                em = channels.get(\"email\", {})\n                em_enabled = st.checkbox(\"Email actif\", value=em.get(\"enabled\", False), key=\"em_enabled\")\n                col1, col2 = st.columns(2)\n                with col1:\n                    em_host = st.text_input(\"Serveur SMTP\", value=em.get(\"smtp_host\", \"smtp.gmail.com\"), key=\"em_host\")\n                    em_port = st.number_input(\"Port SMTP\", value=em.get(\"smtp_port\", 587), min_value=1, key=\"em_port\")\n                    em_tls = st.checkbox(\"Utiliser TLS\", value=em.get(\"use_tls\", True), key=\"em_tls\")\n                    em_user = st.text_input(\"Identifiant\", value=em.get(\"username\", \"\"), key=\"em_user\")\n                    em_pass = st.text_input(\"Mot de passe\", value=em.get(\"password\", \"\"), type=\"password\", key=\"em_pass\")\n                with col2:\n                    em_from = st.text_input(\"Adresse expediteur\", value=em.get(\"from_address\", \"\"), key=\"em_from\")\n                    em_from_name = st.text_input(\"Nom expediteur\", value=em.get(\"from_name\", \"SentinelPi\"), key=\"em_from_name\")\n                    em_to = st.text_area(\"Destinataires (un par ligne)\", value=\"\\n\".join(em.get(\"to_addresses\", [])), key=\"em_to\", height=80)\n                    em_severity = st.selectbox(\"Severite min.\", options=[\"info\", \"notice\", \"warning\", \"critical\"],\n                        index=[\"info\", \"notice\", \"warning\", \"critical\"].index(em.get(\"min_severity\", \"warning\")),\n                        key=\"em_severity\")\n                em_subject = st.text_input(\"Template sujet\", value=em.get(\"subject_template\", \"[SentinelPi] {severity_emoji} {severity}: {title}\"), key=\"em_subject\")\n                em_full = st.checkbox(\"Inclure contenu complet\", value=em.get(\"include_full_content\", True), key=\"em_full\")\n\n            # Webhook\n            with st.expander(\"ðŸ”— Webhook\"):\n                wh = channels.get(\"webhook\", {})\n                wh_enabled = st.checkbox(\"Webhook actif\", value=wh.get(\"enabled\", False), key=\"wh_enabled\")\n                col1, col2 = st.columns(2)\n                with col1:\n                    wh_url = st.text_input(\"URL\", value=wh.get(\"url\", \"\"), key=\"wh_url\")\n                    wh_method = st.selectbox(\"Methode\", options=[\"POST\", \"PUT\", \"PATCH\"],\n                        index=[\"POST\", \"PUT\", \"PATCH\"].index(wh.get(\"method\", \"POST\")) if wh.get(\"method\", \"POST\") in [\"POST\", \"PUT\", \"PATCH\"] else 0,\n                        key=\"wh_method\")\n                with col2:\n                    wh_severity = st.selectbox(\"Severite min.\", options=[\"info\", \"notice\", \"warning\", \"critical\"],\n                        index=[\"info\", \"notice\", \"warning\", \"critical\"].index(wh.get(\"min_severity\", \"notice\")),\n                        key=\"wh_severity\")\n                    wh_timeout = st.number_input(\"Timeout (s)\", value=wh.get(\"timeout\", 30), min_value=1, key=\"wh_timeout\")\n                    wh_retries = st.number_input(\"Max retries\", value=wh.get(\"max_retries\", 3), min_value=0, key=\"wh_retries\")\n                wh_headers_default = _json.dumps(wh.get(\"headers\", {\"Content-Type\": \"application/json\"}), indent=2)\n                wh_headers_str = st.text_area(\"Headers (JSON)\", value=wh_headers_default, height=100, key=\"wh_headers\")\n\n            # Desktop\n            with st.expander(\"ðŸ–¥ Desktop\"):\n                dk = channels.get(\"desktop\", {})\n                dk_enabled = st.checkbox(\"Desktop actif\", value=dk.get(\"enabled\", False), key=\"dk_enabled\")\n                col1, col2 = st.columns(2)\n                with col1:\n                    dk_severity = st.selectbox(\"Severite min.\", options=[\"info\", \"notice\", \"warning\", \"critical\"],\n                        index=[\"info\", \"notice\", \"warning\", \"critical\"].index(dk.get(\"min_severity\", \"warning\")),\n                        key=\"dk_severity\")\n                with col2:\n                    dk_timeout = st.number_input(\"Timeout (s)\", value=dk.get(\"timeout\", 10), min_value=1, key=\"dk_timeout\")\n\n            st.divider()\n\n            # Routing rules\n            st.subheader(\"Regles de routage\")\n            rules = alerting.get(\"rules\", [])\n            rules_text = \"\"\n            for i, rule in enumerate(rules):\n                parts = []\n                if \"category\" in rule:\n                    parts.append(f\"category={rule['category']}\")\n                if \"tags\" in rule:\n                    parts.append(f\"tags={','.join(rule['tags'])}\")\n                parts.append(f\"min_severity={rule.get('min_severity', 'info')}\")\n                parts.append(f\"channels={','.join(rule.get('channels', []))}\")\n                rules_text += \" | \".join(parts) + \"\\n\"\n            rules_input = st.text_area(\n                \"Regles (une par ligne: category=X | tags=a,b | min_severity=Y | channels=c1,c2)\",\n                value=rules_text.strip(),\n                height=150,\n                key=\"routing_rules\",\n            )\n\n            if st.form_submit_button(\"ðŸ’¾ Sauvegarder Alertes\", use_container_width=True):\n                # Parse headers JSON\n                try:\n                    wh_headers_parsed = _json.loads(wh_headers_str) if wh_headers_str.strip() else {}\n                except _json.JSONDecodeError:\n                    wh_headers_parsed = {\"Content-Type\": \"application/json\"}\n\n                # Parse routing rules\n                parsed_rules = []\n                for line in rules_input.strip().split(\"\\n\"):\n                    line = line.strip()\n                    if not line:\n                        continue\n                    rule = {}\n                    for part in line.split(\"|\"):\n                        part = part.strip()\n                        if \"=\" in part:\n                            key, val = part.split(\"=\", 1)\n                            key = key.strip()\n                            val = val.strip()\n                            if key == \"category\":\n                                rule[\"category\"] = val\n                            elif key == \"tags\":\n                                rule[\"tags\"] = [t.strip() for t in val.split(\",\") if t.strip()]\n                            elif key == \"min_severity\":\n                                rule[\"min_severity\"] = val\n                            elif key == \"channels\":\n                                rule[\"channels\"] = [c.strip() for c in val.split(\",\") if c.strip()]\n                    if rule:\n                        parsed_rules.append(rule)\n\n                # Parse email recipients\n                em_to_list = [addr.strip() for addr in em_to.split(\"\\n\") if addr.strip()]\n\n                new_alerts = {\n                    \"alerting\": {\n                        \"enabled\": alert_enabled,\n                        \"aggregation\": {\n                            \"enabled\": agg_enabled,\n                            \"window_minutes\": agg_window,\n                            \"max_alerts_per_window\": agg_max,\n                            \"send_summary\": agg.get(\"send_summary\", True),\n                        },\n                        \"quiet_hours\": {\n                            \"enabled\": qh_enabled,\n                            \"start\": qh_start,\n                            \"end\": qh_end,\n                            \"bypass_for_critical\": qh_bypass,\n                        },\n                        \"channels\": {\n                            \"telegram\": {\n                                \"enabled\": tg_enabled,\n                                \"bot_token\": tg_token,\n                                \"chat_id\": tg_chat,\n                                \"min_severity\": tg_severity,\n                                \"disable_web_preview\": tg_preview,\n                                \"silent\": tg_silent,\n                                \"format\": channels.get(\"telegram\", {}).get(\"format\", \"\"),\n                            },\n                            \"email\": {\n                                \"enabled\": em_enabled,\n                                \"smtp_host\": em_host,\n                                \"smtp_port\": em_port,\n                                \"use_tls\": em_tls,\n                                \"username\": em_user,\n                                \"password\": em_pass,\n                                \"from_address\": em_from,\n                                \"from_name\": em_from_name,\n                                \"to_addresses\": em_to_list,\n                                \"min_severity\": em_severity,\n                                \"subject_template\": em_subject,\n                                \"include_full_content\": em_full,\n                            },\n                            \"webhook\": {\n                                \"enabled\": wh_enabled,\n                                \"url\": wh_url,\n                                \"method\": wh_method,\n                                \"headers\": wh_headers_parsed,\n                                \"min_severity\": wh_severity,\n                                \"timeout\": wh_timeout,\n                                \"max_retries\": wh_retries,\n                            },\n                            \"desktop\": {\n                                \"enabled\": dk_enabled,\n                                \"min_severity\": dk_severity,\n                                \"timeout\": dk_timeout,\n                            },\n                        },\n                        \"rules\": parsed_rules,\n                        \"severity_emojis\": alerting.get(\"severity_emojis\", {\n                            \"info\": \"â„¹ï¸\", \"notice\": \"ðŸ“¢\", \"warning\": \"âš ï¸\", \"critical\": \"ðŸš¨\",\n                        }),\n                    }\n                }\n                try:\n                    _save_alerts_yaml(new_alerts)\n                    st.success(\"Configuration des alertes sauvegardee !\")\n                except Exception as e:\n                    st.error(f\"Erreur: {e}\")\n\n    with tabs[3]:\n        with st.form(\"settings_db\"):\n            db = raw.get(\"database\", {})\n            db_path = st.text_input(\"Chemin DB\", value=db.get(\"path\", \"data/sentinelpi.db\"))\n            db_echo = st.checkbox(\"Afficher SQL (debug)\", value=db.get(\"echo\", False))\n            if st.form_submit_button(\"ðŸ’¾ Sauvegarder DB\", use_container_width=True):\n                new_config = dict(raw)\n                new_config[\"database\"] = {\"path\": db_path, \"echo\": db_echo}\n                try:\n                    _save_settings_yaml(new_config)\n                    st.success(\"Parametres DB sauvegardes !\")\n                except Exception as e:\n                    st.error(f\"Erreur: {e}\")\n\n        # Database reset\n        st.divider()\n        st.subheader(\"Reinitialisation de la base\")\n        st.caption(\"Ces actions sont irreversibles. Toutes les donnees supprimees seront perdues.\")\n\n        col_r1, col_r2 = st.columns(2)\n        with col_r1:\n            st.markdown(\"**Purger les items**\")\n            st.caption(\"Supprime items et alertes, garde sources et filtres\")\n            confirm_purge = st.checkbox(\"Je confirme la purge\", key=\"confirm_purge\")\n            if st.button(\"ðŸ—‘ Purger\", use_container_width=True, disabled=not confirm_purge):\n                with st.spinner(\"Purge en cours...\"):\n                    run_async(reset_database(keep_sources=True))\n                st.success(\"Items et alertes supprimes !\")\n                st.rerun()\n\n        with col_r2:\n            st.markdown(\"**Reinitialisation complete**\")\n            st.caption(\"Supprime tout : items, alertes, sources, filtres\")\n            confirm_reset = st.checkbox(\"Je confirme la reinitialisation\", key=\"confirm_reset\")\n            if st.button(\"ðŸ’£ Tout reinitialiser\", use_container_width=True, disabled=not confirm_reset):\n                with st.spinner(\"Reinitialisation en cours...\"):\n                    run_async(reset_database(keep_sources=False))\n                st.success(\"Base de donnees reinitialisee !\")\n                st.rerun()\n\n    with tabs[4]:\n        with st.form(\"settings_logs\"):\n            log = raw.get(\"logging\", {})\n            col1, col2 = st.columns(2)\n            with col1:\n                log_file = st.text_input(\"Fichier log\", value=log.get(\"file\", \"logs/sentinelpi.log\"))\n                log_rotation = st.text_input(\"Rotation\", value=log.get(\"rotation\", \"10 MB\"))\n            with col2:\n                log_retention = st.text_input(\"Retention\", value=log.get(\"retention\", \"30 days\"))\n                log_colorize = st.checkbox(\"Couleurs console\", value=log.get(\"colorize\", True))\n            if st.form_submit_button(\"ðŸ’¾ Sauvegarder Logs\", use_container_width=True):\n                new_config = dict(raw)\n                new_config[\"logging\"] = {\n                    \"level\": raw.get(\"logging\", {}).get(\"level\", \"INFO\"),\n                    \"file\": log_file,\n                    \"rotation\": log_rotation, \"retention\": log_retention,\n                    \"format\": log.get(\"format\", \"\"),\n                    \"colorize\": log_colorize,\n                }\n                try:\n                    _save_settings_yaml(new_config)\n                    st.success(\"Parametres logs sauvegardes !\")\n                except Exception as e:\n                    st.error(f\"Erreur: {e}\")\n\n    with tabs[5]:\n        with st.form(\"settings_maint\"):\n            maint = raw.get(\"maintenance\", {})\n            col1, col2 = st.columns(2)\n            with col1:\n                maint_cleanup = st.checkbox(\"Nettoyage auto\", value=maint.get(\"cleanup_enabled\", True))\n                maint_retention = st.number_input(\"Retention items (jours)\", value=maint.get(\"retention_days\", 90), min_value=1)\n            with col2:\n                maint_time = st.text_input(\"Heure nettoyage\", value=maint.get(\"cleanup_time\", \"03:00\"))\n                maint_vacuum = st.checkbox(\"Vacuum hebdo\", value=maint.get(\"vacuum_enabled\", True))\n            if st.form_submit_button(\"ðŸ’¾ Sauvegarder Maintenance\", use_container_width=True):\n                new_config = dict(raw)\n                new_config[\"maintenance\"] = {\n                    \"cleanup_enabled\": maint_cleanup,\n                    \"retention_days\": maint_retention,\n                    \"cleanup_time\": maint_time,\n                    \"vacuum_enabled\": maint_vacuum,\n                }\n                try:\n                    _save_settings_yaml(new_config)\n                    st.success(\"Parametres maintenance sauvegardes !\")\n                except Exception as e:\n                    st.error(f\"Erreur: {e}\")\n\n    with tabs[6]:\n        current_hash = raw.get(\"dashboard\", {}).get(\"password_hash\", \"\")\n        if current_hash:\n            st.info(\"Un mot de passe est configure. Les visiteurs non authentifies sont en lecture seule.\")\n        else:\n            st.info(\"Aucun mot de passe configure. Acces libre.\")\n\n        # Require current password if one is set\n        can_edit_pw = True\n        if current_hash:\n            current_pw = st.text_input(\"Mot de passe actuel\", type=\"password\", key=\"current_pw\")\n            if current_pw:\n                if _check_password(current_pw, current_hash):\n                    can_edit_pw = True\n                else:\n                    st.error(\"Mot de passe actuel incorrect\")\n                    can_edit_pw = False\n            else:\n                can_edit_pw = False\n\n        if can_edit_pw:\n            with st.form(\"password_form\"):\n                new_pw = st.text_input(\"Nouveau mot de passe\", type=\"password\", key=\"new_pw\")\n                confirm_pw = st.text_input(\"Confirmer le mot de passe\", type=\"password\", key=\"confirm_pw\")\n\n                col_pw1, col_pw2 = st.columns(2)\n                with col_pw1:\n                    if st.form_submit_button(\"ðŸ”’ Definir\", use_container_width=True):\n                        if new_pw and new_pw == confirm_pw:\n                            new_config = _load_settings_yaml()\n                            new_config.setdefault(\"dashboard\", {})[\"password_hash\"] = _hash_password(new_pw)\n                            try:\n                                _save_settings_yaml(new_config)\n                                st.success(\"Mot de passe mis a jour !\")\n                            except Exception as e:\n                                st.error(f\"Erreur: {e}\")\n                        elif not new_pw:\n                            st.warning(\"Veuillez saisir un mot de passe\")\n                        else:\n                            st.error(\"Les mots de passe ne correspondent pas\")\n                with col_pw2:\n                    if st.form_submit_button(\"ðŸ”“ Supprimer\", use_container_width=True):\n                        new_config = _load_settings_yaml()\n                        new_config.setdefault(\"dashboard\", {}).pop(\"password_hash\", None)\n                        try:\n                            _save_settings_yaml(new_config)\n                            st.success(\"Mot de passe supprime.\")\n                        except Exception as e:\n                            st.error(f\"Erreur: {e}\")\n\n        # Logout\n        st.divider()\n        if st.session_state.get(\"authenticated\"):\n            if st.button(\"ðŸšª Se deconnecter\", use_container_width=True):\n                st.session_state.authenticated = False\n                st.session_state.read_only = False\n                st.rerun()\n\n    # Restart button (outside form)\n    st.divider()\n    st.subheader(\"Redemarrage\")\n    st.caption(\"Redemarrer l'application pour appliquer les changements de configuration.\")\n    if st.button(\"ðŸ”„ Redemarrer l'application\", type=\"primary\"):\n        import subprocess, sys, os, time\n        st.cache_data.clear()\n        st.cache_resource.clear()\n        project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n        subprocess.Popen(\n            [sys.executable, \"-m\", \"streamlit\", \"run\",\n             os.path.abspath(__file__),\n             \"--server.port=8501\", \"--server.address=0.0.0.0\", \"--server.headless=true\"],\n            cwd=project_root\n        )\n        st.info(\"Redemarrage en cours... La page va se recharger automatiquement.\")\n        time.sleep(1)\n        os._exit(0)\n\n\ndef _check_password(password: str, password_hash: str) -> bool:\n    \"\"\"Check if a password matches the stored hash.\"\"\"\n    return hashlib.sha256(password.encode()).hexdigest() == password_hash\n\n\ndef _hash_password(password: str) -> str:\n    \"\"\"Hash a password with SHA-256.\"\"\"\n    return hashlib.sha256(password.encode()).hexdigest()\n\n\ndef render_login_page() -> None:\n    \"\"\"Render the login page.\"\"\"\n    st.markdown(\"### ðŸ›¡ï¸ SentinelPi\")\n    st.markdown(\"---\")\n    st.subheader(\"Connexion\")\n\n    password = st.text_input(\"Mot de passe\", type=\"password\", key=\"login_password\")\n\n    col1, col2 = st.columns(2)\n    with col1:\n        if st.button(\"ðŸ”“ Se connecter\", use_container_width=True, type=\"primary\"):\n            raw = _load_settings_yaml()\n            stored_hash = raw.get(\"dashboard\", {}).get(\"password_hash\", \"\")\n            if stored_hash and _check_password(password, stored_hash):\n                st.session_state.authenticated = True\n                st.session_state.read_only = False\n                st.rerun()\n            else:\n                st.error(\"Mot de passe incorrect\")\n    with col2:\n        if st.button(\"ðŸ‘ Lecture seule\", use_container_width=True):\n            st.session_state.authenticated = False\n            st.session_state.read_only = True\n            st.rerun()\n\n\ndef render_docs_page() -> None:\n    \"\"\"Render the documentation page.\"\"\"\n    st.header(\"ðŸ“š Documentation\")\n\n    st.markdown(\"\"\"\n    Bienvenue dans la documentation de **SentinelPi**, votre station de veille multi-sources.\n    \"\"\")\n\n    # Table of contents\n    tabs = st.tabs([\n        \"ðŸš€ Demarrage\",\n        \"ðŸ“¡ Sources\",\n        \"ðŸŽ¯ Filtres\",\n        \"ðŸ”” Alertes\",\n        \"ðŸ“Š Statistiques\",\n        \"âŒ¨ï¸ CLI\",\n        \"ðŸ”§ Configuration\",\n        \"â“ FAQ\",\n    ])\n\n    # =====================================================\n    # TAB: Getting Started\n    # =====================================================\n    with tabs[0]:\n        st.subheader(\"ðŸš€ Demarrage rapide\")\n\n        st.markdown(\"\"\"\n        ### Qu'est-ce que SentinelPi ?\n\n        SentinelPi est une station de veille autonome qui collecte, filtre et analyse\n        des contenus provenant de multiples sources (RSS, Reddit, Mastodon, YouTube, etc.).\n\n        ### Architecture\n\n        ```\n        Sources (RSS, Web, Social)\n            â†“\n        Collecteurs (async)\n            â†“\n        Deduplication (guid/hash)\n            â†“\n        Filtrage (mots-cles, regex)\n            â†“\n        Enrichissement (keywords, langue)\n            â†“\n        Scoring (pertinence)\n            â†“\n        Stockage (SQLite)\n            â†“\n        Alertes (Telegram, Email, Webhook)\n        ```\n\n        ### Premier lancement\n\n        1. **Configurer les sources** : Allez dans l'onglet ðŸ“¡ Sources et ajoutez vos flux RSS\n        2. **Definir des filtres** : Creez des filtres dans ðŸŽ¯ Filtres pour surveiller des mots-cles\n        3. **Configurer les alertes** : Dans âš™ï¸ Config > Alertes, activez Telegram ou Email\n        4. **Lancer la collecte** : Cliquez sur \"Collecter tout\" ou lancez `sentinelpi` en CLI\n\n        ### Modes de fonctionnement\n\n        | Mode | Commande | Description |\n        |------|----------|-------------|\n        | Continu | `sentinelpi` | Tourne en arriere-plan, collecte selon les intervalles |\n        | Ponctuel | `sentinelpi --once` | Une seule collecte puis arret |\n        | Dashboard | `sentinelpi-dashboard` | Interface web sur le port 8501 |\n        \"\"\")\n\n    # =====================================================\n    # TAB: Sources\n    # =====================================================\n    with tabs[1]:\n        st.subheader(\"ðŸ“¡ Gestion des sources\")\n\n        st.markdown(\"\"\"\n        ### Types de sources supportes\n\n        | Type | Description | Configuration |\n        |------|-------------|---------------|\n        | **RSS** | Flux RSS/Atom standard | URL du flux |\n        | **Web** | Scraping de pages HTML | Selecteurs CSS |\n        | **Reddit** | Subreddits publics | Nom du subreddit, tri |\n        | **Mastodon** | Hashtags ou comptes | Instance, hashtag/compte |\n        | **YouTube** | Chaines YouTube | ID de chaine |\n        | **Custom** | API JSON personnalisee | Mapping des champs |\n\n        ### Ajouter une source RSS\n\n        1. Cliquez sur **âž• Ajouter** dans la page Sources\n        2. Selectionnez le type **rss**\n        3. Entrez le nom et l'URL du flux\n        4. Definissez la categorie (optionnel)\n        5. Ajustez l'intervalle de collecte (defaut: 60 min)\n\n        ### Import/Export OPML\n\n        Vous pouvez importer vos flux depuis un autre lecteur RSS :\n\n        1. Exportez vos flux au format OPML depuis votre ancien lecteur\n        2. Dans SentinelPi, cliquez sur **ðŸ“¤ OPML**\n        3. Uploadez le fichier `.opml`\n        4. Les sources seront importees avec leurs categories\n\n        **Export** : Cliquez sur OPML > Exporter pour sauvegarder vos sources.\n\n        ### Parametres avances\n\n        Dans `config/sources.yaml`, vous pouvez configurer :\n\n        ```yaml\n        - name: \"Mon flux\"\n          type: rss\n          url: \"https://example.com/feed.xml\"\n          category: \"tech\"\n          tags: [\"important\", \"veille\"]\n          interval_minutes: 30\n          priority: 1  # 1=haute, 2=normale, 3=basse\n          enabled: true\n          config:\n            max_items: 50\n            include_content: true\n        ```\n\n        ### Scraping Web\n\n        Pour les sites sans flux RSS :\n\n        ```yaml\n        - name: \"Actualites Concurrent\"\n          type: web\n          url: \"https://example.com/news\"\n          config:\n            selector: \"article.news-item\"\n            title_selector: \"h2\"\n            link_selector: \"a\"\n            date_selector: \".date\"\n            content_selector: \".excerpt\"\n            date_format: \"%d/%m/%Y\"\n        ```\n        \"\"\")\n\n    # =====================================================\n    # TAB: Filters\n    # =====================================================\n    with tabs[2]:\n        st.subheader(\"ðŸŽ¯ Systeme de filtrage\")\n\n        st.markdown(\"\"\"\n        ### Principe\n\n        Les filtres permettent de :\n        - **Inclure** : Ne garder que certains contenus\n        - **Exclure** : Supprimer des contenus non pertinents\n        - **Alerter** : Declencher une notification\n        - **Surligner** : Mettre en evidence dans le flux\n        - **Taguer** : Ajouter des tags automatiques\n\n        ### Types de conditions\n\n        | Type | Description | Exemple |\n        |------|-------------|---------|\n        | **keywords** | Liste de mots-cles | \"cybersecurite\", \"RGPD\" |\n        | **regex** | Expression reguliere | `\\\\bcyber\\\\w+` |\n        | **compound** | Combinaison AND/OR | (A ET B) OU C |\n\n        ### Creer un filtre d'alerte\n\n        1. Allez dans ðŸŽ¯ Filtres > **âž• Nouveau filtre**\n        2. Nom : \"Alerte cybersecurite\"\n        3. Action : **alert**\n        4. Severite : **warning** ou **critical**\n        5. Type de condition : **keywords**\n        6. Champ : **all** (titre + contenu)\n        7. Mots-cles : un par ligne\n           ```\n           cyberattaque\n           ransomware\n           fuite de donnees\n           vulnerabilite\n           ```\n        8. Cliquez sur **Enregistrer**\n\n        ### Modificateur de score\n\n        Chaque filtre peut modifier le score de pertinence :\n        - **+50** : Boost important (tres pertinent)\n        - **+20** : Boost leger\n        - **0** : Neutre\n        - **-20** : Penalite (moins interessant)\n\n        ### Ciblage\n\n        Vous pouvez limiter un filtre a :\n        - **Categories** : `tech, presse`\n        - **Sources specifiques** : IDs des sources\n\n        ### Exemples de filtres\n\n        **Surveillance concurrentielle :**\n        ```yaml\n        name: \"Concurrent A\"\n        action: alert\n        action_params:\n          severity: notice\n        conditions:\n          type: keywords\n          field: all\n          value: [\"Concurrent A\", \"CEO Concurrent\", \"produit-concurrent\"]\n        score_modifier: 30\n        ```\n\n        **Exclusion de spam :**\n        ```yaml\n        name: \"Anti-spam\"\n        action: exclude\n        conditions:\n          type: keywords\n          field: title\n          value: [\"[Sponsored]\", \"[Ad]\", \"Promotion\"]\n        ```\n        \"\"\")\n\n    # =====================================================\n    # TAB: Alerts\n    # =====================================================\n    with tabs[3]:\n        st.subheader(\"ðŸ”” Systeme d'alertes\")\n\n        st.markdown(\"\"\"\n        ### Canaux de notification\n\n        | Canal | Configuration requise | Cas d'usage |\n        |-------|----------------------|-------------|\n        | **Telegram** | Bot token + Chat ID | Alertes mobiles rapides |\n        | **Email** | Serveur SMTP | Rapports, alertes critiques |\n        | **Webhook** | URL endpoint | Integration Slack, Discord, etc. |\n        | **Desktop** | Linux avec notify-send | Alertes locales |\n\n        ### Configurer Telegram\n\n        1. Creez un bot via [@BotFather](https://t.me/botfather) sur Telegram\n        2. Copiez le **Bot Token**\n        3. Demarrez une conversation avec votre bot\n        4. Obtenez votre **Chat ID** via [@userinfobot](https://t.me/userinfobot)\n        5. Dans SentinelPi : âš™ï¸ Config > Alertes > Telegram\n           - Collez le token et le chat ID\n           - Activez le canal\n\n        ### Configurer Email (Gmail)\n\n        1. Activez l'acces \"Applications moins securisees\" ou creez un mot de passe d'application\n        2. Dans SentinelPi : âš™ï¸ Config > Alertes > Email\n           - Serveur SMTP : `smtp.gmail.com`\n           - Port : `587`\n           - TLS : Active\n           - Identifiant : votre email\n           - Mot de passe : mot de passe d'application\n\n        ### Niveaux de severite\n\n        | Niveau | Emoji | Usage |\n        |--------|-------|-------|\n        | **info** | â„¹ï¸ | Information generale |\n        | **notice** | ðŸ“¢ | A noter |\n        | **warning** | âš ï¸ | Attention requise |\n        | **critical** | ðŸš¨ | Action immediate |\n\n        ### Agregation\n\n        Pour eviter le spam d'alertes :\n        - **Fenetre** : Regroupe les alertes sur X minutes\n        - **Max par fenetre** : Limite le nombre d'alertes\n        - **Heures silencieuses** : Pas d'alertes la nuit (sauf critical)\n\n        ### Webhook Discord\n\n        Pour envoyer vers Discord :\n        1. Dans Discord : Parametres du canal > Integrations > Webhooks\n        2. Copiez l'URL du webhook\n        3. Dans SentinelPi, configurez le webhook avec cette URL\n        \"\"\")\n\n    # =====================================================\n    # TAB: Statistics\n    # =====================================================\n    with tabs[4]:\n        st.subheader(\"ðŸ“Š Statistiques et analyses\")\n\n        st.markdown(\"\"\"\n        ### Vue basique\n\n        La page Stats affiche :\n        - **Metriques cles** : Items, alertes, sources, non lus\n        - **Repartition par source** : Camembert des sources actives\n        - **Repartition par categorie** : Distribution des contenus\n        - **Nuage de mots-cles** : Termes les plus frequents\n        - **Top articles** : Items avec le meilleur score\n\n        ### Vue avancee\n\n        Cliquez sur **ðŸ“ˆ Avancees** pour acceder a :\n\n        **Onglet Tendances :**\n        - Items collectes par jour (graphique aire)\n        - Alertes par jour (histogramme)\n        - Evolution cumulative\n\n        **Onglet Sources :**\n        - Items par source (barres horizontales)\n        - Repartition par categorie (camembert)\n        - Score moyen par source\n\n        **Onglet Mots-cles :**\n        - Top 15 mots-cles (barres)\n        - Treemap des mots-cles\n        - Evolution temporelle des 5 premiers mots-cles\n\n        **Onglet Alertes :**\n        - Distribution par severite\n        - Alertes par filtre\n        - Timeline des alertes (stacked area)\n\n        ### Periodes d'analyse\n\n        Selectionnez la periode :\n        - 7 jours (semaine)\n        - 30 jours (mois)\n        - 90 jours (trimestre)\n        - 365 jours (annee)\n        \"\"\")\n\n    # =====================================================\n    # TAB: CLI\n    # =====================================================\n    with tabs[5]:\n        st.subheader(\"âŒ¨ï¸ Interface en ligne de commande\")\n\n        st.markdown(\"\"\"\n        ### Commandes principales\n\n        ```bash\n        # Lancer la collecte en continu\n        sentinelpi\n\n        # Collecter une seule fois\n        sentinelpi --once\n\n        # Lancer le dashboard web\n        sentinelpi-dashboard\n        ```\n\n        ### Import/Export OPML\n\n        ```bash\n        # Exporter les sources RSS vers OPML\n        sentinelpi --export-opml data/mes_flux.opml\n\n        # Importer des sources depuis OPML\n        sentinelpi --import-opml fichier.opml\n        ```\n\n        ### Service systemd\n\n        Pour lancer SentinelPi au demarrage :\n\n        ```bash\n        # Creer le service\n        sudo nano /etc/systemd/system/sentinelpi.service\n        ```\n\n        Contenu :\n        ```ini\n        [Unit]\n        Description=SentinelPi Watch Station\n        After=network.target\n\n        [Service]\n        Type=simple\n        User=pi\n        WorkingDirectory=/home/pi/sentinelpi\n        ExecStart=/home/pi/sentinelpi/venv/bin/sentinelpi\n        Restart=always\n        RestartSec=10\n\n        [Install]\n        WantedBy=multi-user.target\n        ```\n\n        Activation :\n        ```bash\n        sudo systemctl daemon-reload\n        sudo systemctl enable sentinelpi\n        sudo systemctl start sentinelpi\n        ```\n\n        ### Logs\n\n        Les logs sont dans `logs/sentinelpi.log` :\n\n        ```bash\n        # Suivre les logs en temps reel\n        tail -f logs/sentinelpi.log\n\n        # Filtrer les erreurs\n        grep ERROR logs/sentinelpi.log\n        ```\n        \"\"\")\n\n    # =====================================================\n    # TAB: Configuration\n    # =====================================================\n    with tabs[6]:\n        st.subheader(\"ðŸ”§ Fichiers de configuration\")\n\n        st.markdown(\"\"\"\n        ### Structure des fichiers\n\n        ```\n        config/\n        â”œâ”€â”€ settings.yaml    # Parametres generaux\n        â”œâ”€â”€ sources.yaml     # Sources de donnees\n        â”œâ”€â”€ filters.yaml     # Regles de filtrage\n        â””â”€â”€ alerts.yaml      # Configuration des alertes\n        ```\n\n        ### settings.yaml\n\n        ```yaml\n        app:\n          name: \"SentinelPi\"\n          version: \"1.0.0\"\n          timezone: \"Europe/Paris\"\n\n        database:\n          path: \"data/sentinelpi.db\"\n          echo: false  # true pour debug SQL\n\n        collection:\n          default_interval_minutes: 60\n          max_concurrent_collectors: 3\n          max_items_per_source: 100\n          dedup_window_days: 30\n\n        http:\n          timeout: 30\n          max_retries: 3\n          rate_limit: 2  # requetes/seconde\n          user_agent: \"SentinelPi/1.0\"\n\n        scheduler:\n          enabled: true\n          daily_report_time: \"08:00\"\n          weekly_report_day: 0  # 0=lundi\n\n        logging:\n          level: \"INFO\"\n          file: \"logs/sentinelpi.log\"\n          rotation: \"10 MB\"\n          retention: \"30 days\"\n\n        maintenance:\n          cleanup_enabled: true\n          retention_days: 90\n          vacuum_enabled: true\n        ```\n\n        ### Variables d'environnement\n\n        Creez un fichier `.env` a la racine :\n\n        ```env\n        # Telegram\n        TELEGRAM_BOT_TOKEN=123456:ABC...\n        TELEGRAM_CHAT_ID=987654321\n\n        # Email\n        SMTP_PASSWORD=votre_mot_de_passe\n\n        # API keys (pour custom collectors)\n        CUSTOM_API_KEY=xyz123\n        ```\n\n        Dans les fichiers YAML, utilisez `${VAR}` :\n        ```yaml\n        bot_token: \"${TELEGRAM_BOT_TOKEN}\"\n        ```\n\n        ### Base de donnees\n\n        SentinelPi utilise SQLite. La base est dans `data/sentinelpi.db`.\n\n        **Sauvegarde :**\n        ```bash\n        cp data/sentinelpi.db data/backup_$(date +%Y%m%d).db\n        ```\n\n        **Reinitialisation :**\n        Via le dashboard : âš™ï¸ Config > Base de donnees > Reinitialiser\n        \"\"\")\n\n    # =====================================================\n    # TAB: FAQ\n    # =====================================================\n    with tabs[7]:\n        st.subheader(\"â“ Questions frequentes\")\n\n        with st.expander(\"Comment ajouter un flux RSS ?\"):\n            st.markdown(\"\"\"\n            1. Allez dans **ðŸ“¡ Sources**\n            2. Cliquez sur **âž• Ajouter**\n            3. Entrez le nom et l'URL du flux RSS\n            4. Cliquez sur **Enregistrer**\n            \"\"\")\n\n        with st.expander(\"Pourquoi je ne recois pas d'alertes Telegram ?\"):\n            st.markdown(\"\"\"\n            Verifiez :\n            1. Le bot token est correct (obtenu via @BotFather)\n            2. Le chat ID est correct (obtenu via @userinfobot)\n            3. Vous avez demarre une conversation avec le bot\n            4. Le canal Telegram est active dans la config\n            5. La severite minimum n'est pas trop haute\n            \"\"\")\n\n        with st.expander(\"Comment reduire l'utilisation CPU sur Raspberry Pi ?\"):\n            st.markdown(\"\"\"\n            - Augmentez les intervalles de collecte (ex: 120 min au lieu de 60)\n            - Reduisez `max_concurrent_collectors` a 1 ou 2\n            - Desactivez les sources non essentielles\n            - Utilisez `--once` avec cron au lieu du mode continu\n            \"\"\")\n\n        with st.expander(\"Comment surveiller un concurrent ?\"):\n            st.markdown(\"\"\"\n            1. Ajoutez le flux RSS de leur blog/actualites\n            2. Creez un filtre avec action **alert**\n            3. Mots-cles : nom du concurrent, produits, dirigeants\n            4. Severite : **notice** ou **warning**\n            5. Activez les notifications Telegram ou Email\n            \"\"\")\n\n        with st.expander(\"Puis-je utiliser SentinelPi sans Raspberry Pi ?\"):\n            st.markdown(\"\"\"\n            Oui ! SentinelPi fonctionne sur tout systeme Linux/macOS avec Python 3.11+.\n            L'optimisation Raspberry Pi concerne principalement la consommation memoire.\n            \"\"\")\n\n        with st.expander(\"Comment exporter mes donnees ?\"):\n            st.markdown(\"\"\"\n            - **Sources RSS** : Utilisez l'export OPML\n            - **Base complete** : Copiez `data/sentinelpi.db`\n            - **Rapports** : Generes automatiquement dans `data/reports/`\n            \"\"\")\n\n        with st.expander(\"Le dashboard ne demarre pas, que faire ?\"):\n            st.markdown(\"\"\"\n            ```bash\n            # Verifier les erreurs\n            sentinelpi-dashboard 2>&1 | head -50\n\n            # Verifier que le port 8501 est libre\n            netstat -tlnp | grep 8501\n\n            # Lancer manuellement avec debug\n            streamlit run src/dashboard/app.py --logger.level=debug\n            ```\n            \"\"\")\n\n        with st.expander(\"Comment mettre a jour SentinelPi ?\"):\n            st.markdown(\"\"\"\n            ```bash\n            cd /home/pi/sentinelpi\n            git pull origin main\n            pip install -r requirements.txt\n            sudo systemctl restart sentinelpi\n            ```\n            \"\"\")\n\n    # Footer\n    st.divider()\n    st.caption(\"SentinelPi v1.0 - Station de veille multi-sources\")\n\n\ndef main() -> None:\n    \"\"\"Main entry point for the dashboard.\"\"\"\n    # Initialize\n    setup_logging()\n    init_session_state()\n\n    # Custom CSS\n    st.markdown(\"\"\"\n    <style>\n    .stMetric {\n        background-color: #f0f2f6;\n        padding: 10px;\n        border-radius: 5px;\n    }\n    .stDataFrame {\n        font-size: 14px;\n    }\n    /* Modern sidebar nav buttons */\n    section[data-testid=\"stSidebar\"] .stButton > button {\n        border: none !important;\n        border-radius: 8px !important;\n        padding: 0.45rem 0.75rem !important;\n        font-size: 0.88rem !important;\n        text-align: left !important;\n        justify-content: flex-start !important;\n        transition: background 0.15s ease !important;\n    }\n    section[data-testid=\"stSidebar\"] .stButton > button:hover {\n        background: rgba(79, 139, 249, 0.10) !important;\n    }\n    section[data-testid=\"stSidebar\"] .stButton > button[kind=\"primary\"] {\n        background: linear-gradient(90deg, #4f8bf9, #3a6fd8) !important;\n        color: #fff !important;\n        box-shadow: 0 2px 6px rgba(79,139,249,0.3) !important;\n    }\n    section[data-testid=\"stSidebar\"] .stButton > button[kind=\"primary\"]:hover {\n        background: linear-gradient(90deg, #3a6fd8, #2d5fc0) !important;\n    }\n    section[data-testid=\"stSidebar\"] .stButton > button p {\n        text-align: left !important;\n    }\n    /* Hide default sidebar decoration */\n    section[data-testid=\"stSidebar\"] hr {\n        margin: 0.3rem 0 !important;\n        opacity: 0.15 !important;\n    }\n\n    /* Compact action buttons in feed cards */\n    div[data-testid=\"column\"] .stButton > button,\n    div[data-testid=\"column\"] .stPopover > button {\n        padding: 0.15rem 0 !important;\n        min-height: 1.6rem !important;\n    }\n    div[data-testid=\"column\"] .stButton > button p,\n    div[data-testid=\"column\"] .stPopover > button p {\n        font-size: 0.82rem !important;\n        line-height: 1.2 !important;\n        margin: 0 !important;\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n\n    # Check if password protection is configured\n    raw = _load_settings_yaml()\n    password_hash = raw.get(\"dashboard\", {}).get(\"password_hash\", \"\")\n\n    if password_hash:\n        # Password is set, check authentication\n        authenticated = st.session_state.get(\"authenticated\", False)\n        read_only = st.session_state.get(\"read_only\", False)\n\n        if not authenticated and not read_only:\n            render_login_page()\n            return\n    else:\n        # No password set, full access\n        st.session_state.authenticated = True\n        st.session_state.read_only = False\n\n    read_only = st.session_state.get(\"read_only\", False)\n\n    # Render sidebar and get selected page\n    page = render_sidebar()\n\n    # Render selected page\n    if page == \"feed\":\n        render_feed_page()\n    elif page == \"sources\" and not read_only:\n        render_sources_page()\n    elif page == \"filters\" and not read_only:\n        render_filters_page()\n    elif page == \"alerts\" and not read_only:\n        render_alerts_page()\n    elif page == \"stats\":\n        render_stats_page()\n    elif page == \"settings\" and not read_only:\n        render_settings_page()\n    elif page == \"docs\":\n        render_docs_page()\n    elif read_only and page not in (\"feed\", \"stats\", \"docs\"):\n        st.warning(\"Acces restreint en mode lecture seule.\")\n\n\nif __name__ == \"__main__\":\n    main()\n","structuredPatch":[{"oldStart":1968,"oldLines":6,"newStart":1968,"newLines":13,"lines":["                     st.error(f\"Erreur: {e}\")"," ","     with tabs[1]:","+        import json as _json_coll","+","+        # Default browser-like headers","+        DEFAULT_UA = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"","+        DEFAULT_ACCEPT = \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\"","+        DEFAULT_ACCEPT_LANG = \"fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7\"","+","         with st.form(\"settings_collection\"):","             col1, col2 = st.columns(2)","             coll = raw.get(\"collection\", {})"]},{"oldStart":1980,"oldLines":15,"newStart":1987,"newLines":81,"lines":["                 coll_dedup = st.number_input(\"Fenetre dedup (jours)\", value=coll.get(\"dedup_window_days\", 30), min_value=1)"," ","             st.divider()","+            st.subheader(\"ðŸŒ HTTP / Anti-WAF\")","+            st.caption(\"Headers envoyes avec chaque requete pour eviter les blocages (erreurs 403)\")","+","             http = raw.get(\"http\", {})","             col1, col2 = st.columns(2)","             with col1:","                 http_timeout = st.number_input(\"HTTP timeout (s)\", value=http.get(\"timeout\", 30), min_value=5)","                 http_retries = st.number_input(\"HTTP retries\", value=http.get(\"max_retries\", 3), min_value=0)","             with col2:","-                http_rate = st.number_input(\"Rate limit (req/s)\", value=http.get(\"rate_limit\", 2), min_value=1)","-                http_ua = st.text_input(\"User-Agent\", value=http.get(\"user_agent\", \"\"))","+                http_rate = st.number_input(\"Rate limit (req/s)\", value=float(http.get(\"rate_limit\", 2.0)), min_value=0.1, step=0.5)"," ","+            st.markdown(\"**Headers navigateur**\")","+            http_ua = st.text_input(","+                \"User-Agent\",","+                value=http.get(\"user_agent\", DEFAULT_UA),","+                help=\"Identifiant du navigateur simule\"","+            )","+            http_accept = st.text_input(","+                \"Accept\",","+                value=http.get(\"accept\", DEFAULT_ACCEPT),","+                help=\"Types de contenu acceptes\"","+            )","+            http_accept_lang = st.text_input(","+                \"Accept-Language\",","+                value=http.get(\"accept_language\", DEFAULT_ACCEPT_LANG),","+                help=\"Langues preferees\"","+            )","+","+            with st.expander(\"ðŸ”§ Headers avances (Chrome/Chromium)\"):","+                col1, col2 = st.columns(2)","+                with col1:","+                    http_sec_ch_ua = st.text_input(","+                        \"Sec-Ch-Ua\",","+                        value=http.get(\"sec_ch_ua\", '\"Not_A Brand\";v=\"8\", \"Chromium\";v=\"120\", \"Google Chrome\";v=\"120\"'),","+                    )","+                    http_sec_ch_ua_mobile = st.text_input(","+                        \"Sec-Ch-Ua-Mobile\",","+                        value=http.get(\"sec_ch_ua_mobile\", \"?0\"),","+                    )","+                    http_sec_ch_ua_platform = st.text_input(","+                        \"Sec-Ch-Ua-Platform\",","+                        value=http.get(\"sec_ch_ua_platform\", '\"Windows\"'),","+                    )","+                    http_sec_fetch_dest = st.text_input(","+                        \"Sec-Fetch-Dest\",","+                        value=http.get(\"sec_fetch_dest\", \"document\"),","+                    )","+                with col2:","+                    http_sec_fetch_mode = st.text_input(","+                        \"Sec-Fetch-Mode\",","+                        value=http.get(\"sec_fetch_mode\", \"navigate\"),","+                    )","+                    http_sec_fetch_site = st.text_input(","+                        \"Sec-Fetch-Site\",","+                        value=http.get(\"sec_fetch_site\", \"none\"),","+                    )","+                    http_upgrade = st.text_input(","+                        \"Upgrade-Insecure-Requests\",","+                        value=http.get(\"upgrade_insecure_requests\", \"1\"),","+                    )","+                    http_dnt = st.text_input(","+                        \"DNT (Do Not Track)\",","+                        value=http.get(\"dnt\", \"1\"),","+                    )","+","+            with st.expander(\"ðŸ“ Headers personnalises (JSON)\"):","+                st.caption(\"Ajoutez des headers supplementaires au format JSON\")","+                custom_headers_default = http.get(\"custom_headers\", {})","+                http_custom_headers = st.text_area(","+                    \"Custom Headers\",","+                    value=_json_coll.dumps(custom_headers_default, indent=2) if custom_headers_default else \"{}\",","+                    height=100,","+                    placeholder='{\"X-Custom-Header\": \"value\"}',","+                )","+","             st.divider()","             st.subheader(\"Scheduler\")","             sched = raw.get(\"scheduler\", {})"]},{"oldStart":2001,"oldLines":6,"newStart":2074,"newLines":13,"lines":["                 weekly_time = st.text_input(\"Heure rapport hebdo\", value=sched.get(\"weekly_report_time\", \"09:00\"))"," ","             if st.form_submit_button(\"ðŸ’¾ Sauvegarder Collecte\", use_container_width=True):","+                # Parse custom headers","+                try:","+                    custom_headers_parsed = _json_coll.loads(http_custom_headers) if http_custom_headers.strip() else {}","+                except _json_coll.JSONDecodeError:","+                    custom_headers_parsed = {}","+                    st.warning(\"Headers personnalises JSON invalide, ignore\")","+","                 new_config = dict(raw)","                 new_config[\"collection\"] = {","                     \"default_interval_minutes\": coll_interval,"]},{"oldStart":2010,"oldLines":10,"newStart":2090,"newLines":29,"lines":["                     \"collector_timeout\": coll_timeout,","                 }","                 new_config[\"http\"] = {","-                    \"timeout\": http_timeout, \"max_retries\": http_retries,","+                    \"timeout\": http_timeout,","+                    \"max_retries\": http_retries,","                     \"retry_delay\": raw.get(\"http\", {}).get(\"retry_delay\", 5),","-                    \"user_agent\": http_ua, \"rate_limit\": http_rate,","+                    \"rate_limit\": http_rate,","                     \"cache\": raw.get(\"http\", {}).get(\"cache\", {}),","+                    # Browser-like headers","+                    \"user_agent\": http_ua,","+                    \"accept\": http_accept,","+                    \"accept_language\": http_accept_lang,","+                    \"accept_encoding\": \"gzip, deflate, br\",","+                    \"cache_control\": \"no-cache\",","+                    # Sec-Ch headers","+                    \"sec_ch_ua\": http_sec_ch_ua,","+                    \"sec_ch_ua_mobile\": http_sec_ch_ua_mobile,","+                    \"sec_ch_ua_platform\": http_sec_ch_ua_platform,","+                    \"sec_fetch_dest\": http_sec_fetch_dest,","+                    \"sec_fetch_mode\": http_sec_fetch_mode,","+                    \"sec_fetch_site\": http_sec_fetch_site,","+                    \"sec_fetch_user\": \"?1\",","+                    \"upgrade_insecure_requests\": http_upgrade,","+                    \"dnt\": http_dnt,","+                    # Custom headers","+                    \"custom_headers\": custom_headers_parsed,","                 }","                 new_config[\"scheduler\"] = {","                     \"enabled\": sched_enabled,"]},{"oldStart":2025,"oldLines":6,"newStart":2124,"newLines":7,"lines":["                 try:","                     _save_settings_yaml(new_config)","                     st.success(\"Parametres de collecte sauvegardes !\")","+                    st.info(\"Redemarrez l'application pour appliquer les nouveaux headers HTTP\")","                 except Exception as e:","                     st.error(f\"Erreur: {e}\")"," "]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"42b37ab2-885a-404d-8e53-2c4982591045"}
{"parentUuid":"6e57bc52-eb32-484f-915d-643a26a59e10","isSidechain":true,"userType":"external","cwd":"/home/user/sentinelpi","sessionId":"fad99b44-7337-47f8-955b-2384ef483150","version":"2.1.31","gitBranch":"HEAD","agentId":"acompact-116d3d","slug":"reactive-humming-rainbow","type":"user","message":{"role":"user","content":"Your task is to create a detailed summary of the conversation so far, paying close attention to the user's explicit requests and your previous actions.\nThis summary should be thorough in capturing technical details, code patterns, and architectural decisions that would be essential for continuing development work without losing context.\n\nBefore providing your final summary, wrap your analysis in <analysis> tags to organize your thoughts and ensure you've covered all necessary points. In your analysis process:\n\n1. Chronologically analyze each message and section of the conversation. For each section thoroughly identify:\n   - The user's explicit requests and intents\n   - Your approach to addressing the user's requests\n   - Key decisions, technical concepts and code patterns\n   - Specific details like:\n     - file names\n     - full code snippets\n     - function signatures\n     - file edits\n  - Errors that you ran into and how you fixed them\n  - Pay special attention to specific user feedback that you received, especially if the user told you to do something differently.\n2. Double-check for technical accuracy and completeness, addressing each required element thoroughly.\n\nYour summary should include the following sections:\n\n1. Primary Request and Intent: Capture all of the user's explicit requests and intents in detail\n2. Key Technical Concepts: List all important technical concepts, technologies, and frameworks discussed.\n3. Files and Code Sections: Enumerate specific files and code sections examined, modified, or created. Pay special attention to the most recent messages and include full code snippets where applicable and include a summary of why this file read or edit is important.\n4. Errors and fixes: List all errors that you ran into, and how you fixed them. Pay special attention to specific user feedback that you received, especially if the user told you to do something differently.\n5. Problem Solving: Document problems solved and any ongoing troubleshooting efforts.\n6. All user messages: List ALL user messages that are not tool results. These are critical for understanding the users' feedback and changing intent.\n6. Pending Tasks: Outline any pending tasks that you have explicitly been asked to work on.\n7. Current Work: Describe in detail precisely what was being worked on immediately before this summary request, paying special attention to the most recent messages from both user and assistant. Include file names and code snippets where applicable.\n8. Optional Next Step: List the next step that you will take that is related to the most recent work you were doing. IMPORTANT: ensure that this step is DIRECTLY in line with the user's most recent explicit requests, and the task you were working on immediately before this summary request. If your last task was concluded, then only list next steps if they are explicitly in line with the users request. Do not start on tangential requests or really old requests that were already completed without confirming with the user first.\n                       If there is a next step, include direct quotes from the most recent conversation showing exactly what task you were working on and where you left off. This should be verbatim to ensure there's no drift in task interpretation.\n\nHere's an example of how your output should be structured:\n\n<example>\n<analysis>\n[Your thought process, ensuring all points are covered thoroughly and accurately]\n</analysis>\n\n<summary>\n1. Primary Request and Intent:\n   [Detailed description]\n\n2. Key Technical Concepts:\n   - [Concept 1]\n   - [Concept 2]\n   - [...]\n\n3. Files and Code Sections:\n   - [File Name 1]\n      - [Summary of why this file is important]\n      - [Summary of the changes made to this file, if any]\n      - [Important Code Snippet]\n   - [File Name 2]\n      - [Important Code Snippet]\n   - [...]\n\n4. Errors and fixes:\n    - [Detailed description of error 1]:\n      - [How you fixed the error]\n      - [User feedback on the error if any]\n    - [...]\n\n5. Problem Solving:\n   [Description of solved problems and ongoing troubleshooting]\n\n6. All user messages: \n    - [Detailed non tool use user message]\n    - [...]\n\n7. Pending Tasks:\n   - [Task 1]\n   - [Task 2]\n   - [...]\n\n8. Current Work:\n   [Precise description of current work]\n\n9. Optional Next Step:\n   [Optional Next step to take]\n\n</summary>\n</example>\n\nPlease provide your summary based on the conversation so far, following this structure and ensuring precision and thoroughness in your response. \n\nThere may be additional summarization instructions provided in the included context. If so, remember to follow these instructions when creating the above summary. Examples of instructions include:\n<example>\n## Compact Instructions\nWhen summarizing the conversation focus on typescript code changes and also remember the mistakes you made and how you fixed them.\n</example>\n\n<example>\n# Summary instructions\nWhen you are using compact - please focus on test output and code changes. Include file reads verbatim.\n</example>\n\n\nIMPORTANT: Do NOT use any tools. You MUST respond with ONLY the <summary>...</summary> block as your text output."},"uuid":"141a5acb-2211-4b83-b3a7-918c87b1afab","timestamp":"2026-02-05T20:30:13.533Z"}
{"parentUuid":"141a5acb-2211-4b83-b3a7-918c87b1afab","isSidechain":true,"userType":"external","cwd":"/home/user/sentinelpi","sessionId":"fad99b44-7337-47f8-955b-2384ef483150","version":"2.1.31","gitBranch":"HEAD","agentId":"acompact-116d3d","slug":"reactive-humming-rainbow","message":{"model":"claude-opus-4-5-20251101","id":"msg_0163VKkju4KJh7Mgz52vxMkn","type":"message","role":"assistant","content":[{"type":"text","text":"<analysis>\nLet me chronologically analyze the conversation:\n\n1. Initial request: User asked for feature proposals for SentinelPi\n2. I explored the codebase and proposed 12 features\n3. User selected features 5 (OPML Export/Import) and 9 (Advanced Statistics)\n4. I implemented both features:\n   - Created src/utils/opml.py for OPML handling\n   - Created src/dashboard/components/statistics.py for advanced stats with Plotly\n   - Modified src/dashboard/app.py to integrate both\n   - Added plotly to requirements.txt and pyproject.toml\n   - Added CLI commands for OPML in src/main.py\n   - Created tests/test_opml.py\n\n5. User requested: \"ajoute dans la navbar un pannel en plus 'Documentation'\"\n   - I added a Documentation page with 8 tabs covering all aspects of the app\n   - Modified render_sidebar() to add the docs nav item\n   - Created render_docs_page() function with comprehensive documentation\n\n6. User requested: \"possibilitÃ© de supprimer une source\"\n   - Added _delete_source() async function in src/dashboard/components/sources.py\n   - Added delete button with confirmation popover in the sources table\n\n7. User requested: \"possibilitÃ© de trier les flux par source\"\n   - Modified get_feed_items() to add source_id and sort_by parameters\n   - Modified render_feed_page() to add source filter and sort dropdown\n\n8. User requested: \"possibilitÃ© de trier les flux par filtre\"\n   - Modified get_feed_items() to add filter_id parameter\n   - Added filter selector in the feed page showing all filters with icons\n\n9. User requested: \"possibilitÃ© de modifier une source\"\n   - Added _update_source() and _get_source_by_id() in sources.py\n   - Created edit_source_dialog() with full editing capabilities\n   - Added Edit column with âœï¸ button in sources table\n\n10. User requested: \"j'ai souvent des erreurs 403, ajoute dans les paramÃ¨tres la possibilitÃ© de modifier les headers pour la collecte\"\n    - Modified src/utils/config.py HttpConfig class to include browser-like headers\n    - Modified src/utils/http.py to use the new headers\n    - Modified settings page in app.py to allow editing all HTTP headers\n\nKey files modified:\n- src/utils/opml.py (created)\n- src/dashboard/components/statistics.py (created)\n- src/dashboard/components/sources.py (modified)\n- src/dashboard/app.py (heavily modified)\n- src/utils/config.py (modified)\n- src/utils/http.py (modified)\n- src/main.py (modified)\n- requirements.txt (modified)\n- pyproject.toml (modified)\n- tests/test_opml.py (created)\n\nThe most recent work was adding HTTP headers configuration to avoid 403 errors from WAFs.\n</analysis>\n\n<summary>\n1. Primary Request and Intent:\n   The user requested multiple feature additions to SentinelPi, a multi-source monitoring station for Raspberry Pi:\n   - Feature proposals for the application\n   - Implementation of OPML export/import (feature 5)\n   - Implementation of advanced statistics with Plotly charts (feature 9)\n   - Documentation page in the navbar\n   - Ability to delete sources\n   - Ability to filter/sort feed items by source\n   - Ability to filter feed items by filter (rule)\n   - Ability to edit/modify existing sources\n   - HTTP headers configuration to avoid 403 WAF blocks, with browser-like defaults\n\n2. Key Technical Concepts:\n   - Streamlit dashboard with navigation and dialogs\n   - SQLAlchemy async ORM with SQLite\n   - OPML XML format for RSS feed exchange\n   - Plotly for interactive charts\n   - HTTP client with anti-WAF headers (User-Agent, Sec-Ch-*, etc.)\n   - Pydantic configuration models\n   - Async/await patterns throughout\n\n3. Files and Code Sections:\n\n   - **src/utils/opml.py** (created)\n     - Complete OPML import/export module\n     - Functions: export_sources_to_opml(), parse_opml(), import_opml_to_database(), export_database_to_opml()\n     - Supports category folders, duplicate detection\n\n   - **src/dashboard/components/statistics.py** (created)\n     - Advanced statistics with Plotly charts\n     - Functions: render_statistics_page(), render_kpi_cards(), render_trends_tab(), render_sources_tab(), render_keywords_tab(), render_alerts_tab(), get_advanced_stats()\n\n   - **src/dashboard/components/sources.py** (modified)\n     - Added source management functions:\n     ```python\n     async def _delete_source(source_id: str) -> bool:\n         \"\"\"Delete a source and all its items from the database.\"\"\"\n     \n     async def _update_source(source_id, name, url, category, interval_minutes, priority, enabled, tags, config) -> bool:\n         \"\"\"Update a source in the database.\"\"\"\n     \n     async def _get_source_by_id(source_id: str):\n         \"\"\"Get a source by its ID.\"\"\"\n     ```\n\n   - **src/utils/config.py** (modified)\n     - Enhanced HttpConfig with browser-like headers:\n     ```python\n     class HttpConfig(BaseModel):\n         user_agent: str = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36...\"\n         accept: str = \"text/html,application/xhtml+xml,application/xml;q=0.9...\"\n         accept_language: str = \"fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7\"\n         sec_ch_ua: str = '\"Not_A Brand\";v=\"8\", \"Chromium\";v=\"120\"...'\n         # ... many more Sec-* headers\n         custom_headers: dict[str, str] = Field(default_factory=dict)\n         \n         def get_headers(self) -> dict[str, str]:\n             \"\"\"Get all headers as a dictionary.\"\"\"\n     ```\n\n   - **src/utils/http.py** (modified)\n     - Updated _get_client() to use all configured headers:\n     ```python\n     async def _get_client(self) -> httpx.AsyncClient:\n         settings = get_settings()\n         headers = settings.http.get_headers()\n         self._client = httpx.AsyncClient(\n             timeout=httpx.Timeout(self.timeout),\n             headers=headers,\n             follow_redirects=True,\n         )\n     ```\n\n   - **src/dashboard/app.py** (heavily modified)\n     - Added render_docs_page() with 8 documentation tabs\n     - Added edit_source_dialog() for source editing\n     - Modified render_feed_page() with source, filter, and sort selectors\n     - Modified render_sources_page() with Edit and Delete columns\n     - Modified render_settings_page() tabs[1] with full HTTP headers configuration UI\n     - Modified get_feed_items() to support source_id, filter_id, sort_by parameters\n\n   - **src/main.py** (modified)\n     - Added CLI commands: --export-opml and --import-opml\n\n   - **requirements.txt** and **pyproject.toml** (modified)\n     - Added plotly>=5.18.0 dependency\n\n   - **tests/test_opml.py** (created)\n     - Unit tests for OPML export/import functionality\n\n4. Errors and fixes:\n   - Initial OPML module import test failed due to missing loguru dependency (not installed in test environment) - verified syntax with py_compile instead\n   - All syntax verifications passed with `python3 -m py_compile`\n\n5. Problem Solving:\n   - Implemented browser-like HTTP headers to solve 403 WAF blocking issues\n   - Used LIKE query on JSON field for filter matching in feed items\n   - Used popover for delete confirmation to prevent accidental deletions\n   - Dynamic category list derived from actual sources in database\n\n6. All user messages:\n   - \"propose des features\"\n   - \"fait le 5 et 9\" (implement features 5 and 9)\n   - \"ajoute dans la navbar un pannel en plus 'Documentation' qui explique tout ce qu'il faut savoir pour utiliser l'app\"\n   - \"possibilitÃ© de supprimer une source\"\n   - \"possibilitÃ© de trier les flux par source\"\n   - \"possibilitÃ© de trier les flux par filtre\"\n   - \"possibilitÃ© de modifier une source\"\n   - \"j'ai souvent des erreurs 403, ajoute dans les paramÃ¨tres la possibilitÃ© de modifier les headers pour la collecte et personnalisÃ© la requete pour pas etre bloquÃ© par les waf, mets des paramÃ¨tres par dÃ©faut permettant de pas etre bloquÃ© pour imiter un navigateur\"\n\n7. Pending Tasks:\n   - None explicitly requested - the last task (HTTP headers configuration) was completed\n\n8. Current Work:\n   The most recent work was implementing HTTP headers configuration to avoid 403 WAF blocks. I:\n   - Modified `src/utils/config.py` to add comprehensive browser-like headers (User-Agent, Accept, Accept-Language, Sec-Ch-*, Sec-Fetch-*, DNT, etc.)\n   - Added a `get_headers()` method to return all headers as a dictionary\n   - Modified `src/utils/http.py` to use these headers in the async client\n   - Added a complete HTTP headers configuration UI in the settings page (tabs[1]) with:\n     - Basic headers (User-Agent, Accept, Accept-Language)\n     - Advanced Chrome headers in an expander\n     - Custom headers JSON editor\n   - The syntax was verified successfully\n\n9. Optional Next Step:\n   The HTTP headers configuration task was completed. No explicit next step was requested by the user. The last verification showed \"Syntax OK\" for all modified files. If continuing, I would wait for user feedback on whether the 403 errors are resolved or if additional adjustments are needed.\n</summary>"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":4808,"cache_read_input_tokens":165990,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":4808},"output_tokens":5,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CXqZBKY1tGSrzbfjGX7UW","type":"assistant","uuid":"52f20d91-2faa-4fe0-b5b8-f0a8e7ceb54f","timestamp":"2026-02-05T20:30:58.529Z"}
