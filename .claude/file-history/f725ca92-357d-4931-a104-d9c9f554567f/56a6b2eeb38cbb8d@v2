"""
HTTP client for SentinelPi.

Provides an async HTTP client with retry logic, rate limiting, and caching.
"""

from __future__ import annotations

import asyncio
import hashlib
import time
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any

import httpx
from diskcache import Cache
from tenacity import (
    retry,
    retry_if_exception_type,
    stop_after_attempt,
    wait_exponential,
)

from src.utils.config import get_settings
from src.utils.logging import create_logger

log = create_logger("utils.http")


@dataclass
class HttpResponse:
    """Wrapper for HTTP response data."""

    status_code: int
    headers: dict[str, str]
    text: str
    url: str
    elapsed_ms: float
    from_cache: bool = False

    @property
    def ok(self) -> bool:
        """Check if response was successful (2xx)."""
        return 200 <= self.status_code < 300

    @property
    def content(self) -> bytes:
        """Get response content as bytes."""
        return self.text.encode("utf-8")


@dataclass
class RateLimiter:
    """Simple token bucket rate limiter."""

    rate: float  # requests per second
    _tokens: float = field(init=False)
    _last_update: float = field(init=False)
    _lock: asyncio.Lock = field(init=False, default_factory=asyncio.Lock)

    def __post_init__(self) -> None:
        self._tokens = self.rate
        self._last_update = time.monotonic()

    async def acquire(self) -> None:
        """Acquire a token, waiting if necessary."""
        async with self._lock:
            now = time.monotonic()
            elapsed = now - self._last_update
            self._tokens = min(self.rate, self._tokens + elapsed * self.rate)
            self._last_update = now

            if self._tokens < 1:
                wait_time = (1 - self._tokens) / self.rate
                log.debug(f"Rate limiting: waiting {wait_time:.2f}s")
                await asyncio.sleep(wait_time)
                self._tokens = 0
            else:
                self._tokens -= 1


class HttpClient:
    """
    Async HTTP client with retry, rate limiting, and caching.

    Features:
    - Automatic retries with exponential backoff
    - Rate limiting to avoid overwhelming servers
    - Disk-based response caching
    - Configurable timeouts and headers
    """

    def __init__(
        self,
        timeout: float | None = None,
        max_retries: int | None = None,
        rate_limit: float | None = None,
        user_agent: str | None = None,
        cache_enabled: bool | None = None,
        cache_ttl: int | None = None,
    ) -> None:
        """
        Initialize the HTTP client.

        Args:
            timeout: Request timeout in seconds.
            max_retries: Maximum number of retry attempts.
            rate_limit: Maximum requests per second.
            user_agent: User-Agent header value.
            cache_enabled: Whether to enable response caching.
            cache_ttl: Cache TTL in seconds.
        """
        settings = get_settings()
        http_config = settings.http

        self.timeout = timeout or http_config.timeout
        self.max_retries = max_retries or http_config.max_retries
        self.user_agent = user_agent or http_config.user_agent

        # Rate limiter
        rate = rate_limit or http_config.rate_limit
        self._rate_limiter = RateLimiter(rate=rate)

        # Cache
        self._cache_enabled = cache_enabled if cache_enabled is not None else http_config.cache.enabled
        self._cache_ttl = cache_ttl or http_config.cache.ttl_seconds
        self._cache: Cache | None = None

        if self._cache_enabled:
            cache_dir = http_config.cache.path
            cache_dir.mkdir(parents=True, exist_ok=True)
            self._cache = Cache(str(cache_dir))
            log.debug(f"HTTP cache enabled: {cache_dir}")

        # HTTP client (created lazily)
        self._client: httpx.AsyncClient | None = None

    async def _get_client(self) -> httpx.AsyncClient:
        """Get or create the async HTTP client."""
        if self._client is None or self._client.is_closed:
            self._client = httpx.AsyncClient(
                timeout=httpx.Timeout(self.timeout),
                headers={"User-Agent": self.user_agent},
                follow_redirects=True,
                http2=True,
            )
        return self._client

    def _cache_key(self, method: str, url: str, **kwargs: Any) -> str:
        """Generate a cache key for a request."""
        key_data = f"{method}:{url}:{sorted(kwargs.items())}"
        return hashlib.sha256(key_data.encode()).hexdigest()

    def _get_cached(self, key: str) -> HttpResponse | None:
        """Get a cached response if available and not expired."""
        if not self._cache_enabled or self._cache is None:
            return None

        try:
            cached = self._cache.get(key)
            if cached is not None:
                log.debug(f"Cache hit for key {key[:16]}...")
                return cached
        except Exception as e:
            log.warning(f"Cache read error: {e}")

        return None

    def _set_cached(self, key: str, response: HttpResponse) -> None:
        """Cache a response."""
        if not self._cache_enabled or self._cache is None:
            return

        try:
            self._cache.set(key, response, expire=self._cache_ttl)
            log.debug(f"Cached response for key {key[:16]}...")
        except Exception as e:
            log.warning(f"Cache write error: {e}")

    async def _request(
        self,
        method: str,
        url: str,
        use_cache: bool = True,
        **kwargs: Any,
    ) -> HttpResponse:
        """
        Make an HTTP request with retry logic.

        Args:
            method: HTTP method (GET, POST, etc.).
            url: Request URL.
            use_cache: Whether to use caching for this request.
            **kwargs: Additional arguments passed to httpx.

        Returns:
            HttpResponse object.

        Raises:
            httpx.HTTPError: If the request fails after all retries.
        """
        # Check cache first (only for GET requests)
        if use_cache and method.upper() == "GET":
            cache_key = self._cache_key(method, url, **kwargs)
            cached = self._get_cached(cache_key)
            if cached is not None:
                cached.from_cache = True
                return cached
        else:
            cache_key = None

        # Apply rate limiting
        await self._rate_limiter.acquire()

        # Make request with retry
        client = await self._get_client()

        @retry(
            retry=retry_if_exception_type((httpx.TransportError, httpx.TimeoutException)),
            stop=stop_after_attempt(self.max_retries),
            wait=wait_exponential(multiplier=1, min=1, max=30),
            reraise=True,
        )
        async def _do_request() -> httpx.Response:
            log.debug(f"{method} {url}")
            return await client.request(method, url, **kwargs)

        start_time = time.monotonic()
        try:
            response = await _do_request()
            elapsed_ms = (time.monotonic() - start_time) * 1000

            result = HttpResponse(
                status_code=response.status_code,
                headers=dict(response.headers),
                text=response.text,
                url=str(response.url),
                elapsed_ms=elapsed_ms,
                from_cache=False,
            )

            # Cache successful GET responses
            if cache_key and result.ok:
                self._set_cached(cache_key, result)

            log.debug(
                f"{method} {url} -> {result.status_code} ({elapsed_ms:.0f}ms)"
            )
            return result

        except Exception as e:
            elapsed_ms = (time.monotonic() - start_time) * 1000
            log.error(f"{method} {url} failed after {elapsed_ms:.0f}ms: {e}")
            raise

    async def get(
        self,
        url: str,
        use_cache: bool = True,
        **kwargs: Any,
    ) -> HttpResponse:
        """
        Make a GET request.

        Args:
            url: Request URL.
            use_cache: Whether to use caching.
            **kwargs: Additional arguments.

        Returns:
            HttpResponse object.
        """
        return await self._request("GET", url, use_cache=use_cache, **kwargs)

    async def post(
        self,
        url: str,
        **kwargs: Any,
    ) -> HttpResponse:
        """
        Make a POST request.

        Args:
            url: Request URL.
            **kwargs: Additional arguments (data, json, etc.).

        Returns:
            HttpResponse object.
        """
        return await self._request("POST", url, use_cache=False, **kwargs)

    async def head(
        self,
        url: str,
        **kwargs: Any,
    ) -> HttpResponse:
        """
        Make a HEAD request.

        Args:
            url: Request URL.
            **kwargs: Additional arguments.

        Returns:
            HttpResponse object.
        """
        return await self._request("HEAD", url, use_cache=False, **kwargs)

    async def close(self) -> None:
        """Close the HTTP client and cache."""
        if self._client is not None:
            await self._client.aclose()
            self._client = None

        if self._cache is not None:
            self._cache.close()
            self._cache = None

        log.debug("HTTP client closed")

    async def __aenter__(self) -> "HttpClient":
        """Async context manager entry."""
        return self

    async def __aexit__(self, *args: Any) -> None:
        """Async context manager exit."""
        await self.close()


# Global client instance (lazy loaded)
_client: HttpClient | None = None


def get_http_client() -> HttpClient:
    """
    Get the global HTTP client instance.

    Returns:
        The global HttpClient instance.
    """
    global _client
    if _client is None:
        _client = HttpClient()
    return _client


async def close_http_client() -> None:
    """Close the global HTTP client."""
    global _client
    if _client is not None:
        await _client.close()
        _client = None
