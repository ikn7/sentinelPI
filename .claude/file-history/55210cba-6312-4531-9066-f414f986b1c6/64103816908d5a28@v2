"""Collecteur de textes juridiques via Légifrance.

Légifrance est le service public de diffusion du droit français :
- Lois et ordonnances
- Décrets et arrêtés
- Codes en vigueur
- Jurisprudence
- Conventions collectives

Sources :
- API PISTE : https://piste.gouv.fr/ (nécessite inscription)
- Flux RSS JORF : https://www.legifrance.gouv.fr/rss/
- Open Data : https://echanges.dila.gouv.fr/OPENDATA/
"""

import hashlib
import re
from dataclasses import dataclass, field
from datetime import date, datetime
from typing import Any, Optional

import feedparser
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from src.collectors.base import BaseCollector, CollectionResult
from src.config import get_settings, load_sectors
from src.storage.models import Regulation, RegulationDeadline, generate_uuid
from src.utils.logging import get_logger

logger = get_logger(__name__)


# URLs des flux RSS Légifrance/JORF
LEGIFRANCE_RSS_FEEDS = {
    "jorf": "https://www.legifrance.gouv.fr/jorf/rss",
    "lois": "https://www.legifrance.gouv.fr/eli/loi/rss",
    "decrets": "https://www.legifrance.gouv.fr/eli/decret/rss",
    "arretes": "https://www.legifrance.gouv.fr/eli/arrete/rss",
}

# API PISTE (si disponible)
PISTE_API_BASE = "https://api.piste.gouv.fr/dila/legifrance/lf-engine-app"


# Types de textes juridiques
TEXT_TYPES = {
    "loi": "loi",
    "ordonnance": "ordonnance",
    "décret": "decret",
    "arrêté": "arrete",
    "règlement": "reglement_ue",
    "directive": "directive_ue",
    "décision": "decision",
    "avis": "avis",
    "circulaire": "circulaire",
}


@dataclass
class LegalText:
    """Texte juridique parsé."""

    type: str
    numero: Optional[str]
    titre: str
    titre_court: Optional[str] = None
    date_signature: Optional[date] = None
    date_publication: Optional[date] = None
    date_entree_vigueur: Optional[date] = None
    source: str = "legifrance"
    url: str = ""
    contenu: Optional[str] = None
    resume: Optional[str] = None
    mots_cles: list[str] = field(default_factory=list)
    nor: Optional[str] = None  # Numéro NOR


class LegifranceCollector(BaseCollector[Regulation]):
    """Collecteur de textes juridiques français via Légifrance.

    Surveille les nouvelles publications au JORF et les textes
    pertinents pour les secteurs configurés.

    Example:
        async with LegifranceCollector() as collector:
            regulations = await collector.collect_recent()
    """

    name = "legifrance"
    source_name = "legifrance"

    def __init__(self, session: Optional[AsyncSession] = None) -> None:
        """Initialise le collecteur Légifrance."""
        super().__init__(session)
        self._nor_pattern = re.compile(r'NOR\s*:\s*([A-Z]{4}\d{7}[A-Z])')
        self._date_pattern = re.compile(r'(\d{1,2})\s+(janvier|février|mars|avril|mai|juin|juillet|août|septembre|octobre|novembre|décembre)\s+(\d{4})', re.IGNORECASE)

    def _parse_french_date(self, text: str) -> Optional[date]:
        """Parse une date en français.

        Args:
            text: Texte contenant une date.

        Returns:
            Objet date ou None.
        """
        months = {
            "janvier": 1, "février": 2, "mars": 3, "avril": 4,
            "mai": 5, "juin": 6, "juillet": 7, "août": 8,
            "septembre": 9, "octobre": 10, "novembre": 11, "décembre": 12,
        }

        match = self._date_pattern.search(text)
        if match:
            day = int(match.group(1))
            month = months.get(match.group(2).lower())
            year = int(match.group(3))
            if month:
                try:
                    return date(year, month, day)
                except ValueError:
                    pass
        return None

    def _parse_iso_date(self, date_str: Optional[str]) -> Optional[date]:
        """Parse une date ISO.

        Args:
            date_str: Date au format ISO ou autre.

        Returns:
            Objet date ou None.
        """
        if not date_str:
            return None

        formats = [
            "%Y-%m-%d",
            "%d/%m/%Y",
            "%Y-%m-%dT%H:%M:%S",
            "%Y-%m-%dT%H:%M:%SZ",
        ]

        for fmt in formats:
            try:
                return datetime.strptime(date_str.split("+")[0].strip(), fmt).date()
            except ValueError:
                continue

        return self._parse_french_date(date_str)

    def _extract_nor(self, text: str) -> Optional[str]:
        """Extrait le numéro NOR d'un texte.

        Args:
            text: Texte contenant potentiellement un NOR.

        Returns:
            Numéro NOR ou None.
        """
        match = self._nor_pattern.search(text)
        if match:
            return match.group(1)
        return None

    def _determine_text_type(self, titre: str) -> str:
        """Détermine le type de texte juridique.

        Priorise le mot-clé qui apparaît le plus tôt dans le titre.

        Args:
            titre: Titre du texte.

        Returns:
            Type normalisé.
        """
        titre_lower = titre.lower()

        # Trouver le mot-clé qui apparaît le plus tôt dans le titre
        best_match = None
        best_position = len(titre_lower) + 1

        for keyword, text_type in TEXT_TYPES.items():
            position = titre_lower.find(keyword)
            if position != -1 and position < best_position:
                best_position = position
                best_match = text_type

        return best_match or "autre"

    def _extract_short_title(self, titre: str) -> Optional[str]:
        """Extrait un titre court du titre complet.

        Args:
            titre: Titre complet.

        Returns:
            Titre court ou None.
        """
        # Chercher un titre entre guillemets
        match = re.search(r'[«"](.*?)[»"]', titre)
        if match:
            return match.group(1)

        # Limiter à 100 caractères
        if len(titre) > 100:
            return titre[:97] + "..."

        return None

    def _generate_hash(self, text: LegalText) -> str:
        """Génère un hash unique pour un texte.

        Args:
            text: Texte juridique.

        Returns:
            Hash MD5.
        """
        content = f"{text.type}:{text.numero}:{text.titre}"
        return hashlib.md5(content.encode()).hexdigest()

    def _matches_sector_keywords(
        self,
        text: LegalText,
        keywords: list[str],
    ) -> bool:
        """Vérifie si un texte correspond aux mots-clés d'un secteur.

        Args:
            text: Texte juridique.
            keywords: Mots-clés du secteur.

        Returns:
            True si correspondance trouvée.
        """
        search_text = f"{text.titre} {text.resume or ''} {text.contenu or ''}".lower()

        for keyword in keywords:
            if keyword.lower() in search_text:
                return True

        return False

    def _parse_rss_entry(self, entry: dict[str, Any]) -> Optional[LegalText]:
        """Parse une entrée du flux RSS.

        Args:
            entry: Entrée feedparser.

        Returns:
            LegalText ou None.
        """
        try:
            titre = entry.get("title", "")
            if not titre:
                return None

            # Extraire le contenu/résumé
            summary = entry.get("summary", "") or entry.get("description", "")

            # Déterminer le type
            text_type = self._determine_text_type(titre)

            # Extraire le NOR
            nor = self._extract_nor(f"{titre} {summary}")

            # Parser les dates
            date_pub = self._parse_iso_date(entry.get("published"))
            date_sig = self._parse_french_date(titre)

            # URL
            url = entry.get("link", "")

            return LegalText(
                type=text_type,
                numero=nor,
                titre=titre,
                titre_court=self._extract_short_title(titre),
                date_signature=date_sig,
                date_publication=date_pub or date.today(),
                source="legifrance",
                url=url,
                resume=summary[:500] if summary else None,
                nor=nor,
            )

        except Exception as e:
            self._logger.warning(f"Erreur parsing entrée RSS: {e}")
            return None

    async def _fetch_rss_feed(self, feed_name: str) -> list[LegalText]:
        """Récupère les textes depuis un flux RSS.

        Args:
            feed_name: Nom du flux.

        Returns:
            Liste des textes juridiques.
        """
        url = LEGIFRANCE_RSS_FEEDS.get(feed_name)
        if not url:
            self._logger.error(f"Flux RSS inconnu: {feed_name}")
            return []

        try:
            response = await self.client.get_text(url, use_cache=False)
            feed = feedparser.parse(response)

            texts = []
            for item in feed.entries:
                text = self._parse_rss_entry(item)
                if text:
                    texts.append(text)

            self._logger.info(f"Flux {feed_name}: {len(texts)} textes")
            return texts

        except Exception as e:
            self._logger.error(f"Erreur récupération flux RSS {feed_name}: {e}")
            return []

    async def _search_by_keywords(
        self,
        keywords: list[str],
        text_type: Optional[str] = None,
        date_start: Optional[date] = None,
    ) -> list[LegalText]:
        """Recherche des textes par mots-clés (via flux RSS filtré).

        Note: Sans API PISTE, on filtre les résultats RSS.

        Args:
            keywords: Mots-clés de recherche.
            text_type: Type de texte (optionnel).
            date_start: Date de début (optionnel).

        Returns:
            Liste des textes correspondants.
        """
        all_texts: list[LegalText] = []

        # Récupérer tous les flux RSS pertinents
        feed_names = ["jorf"]
        if text_type:
            if text_type in ["loi", "ordonnance"]:
                feed_names.append("lois")
            elif text_type == "decret":
                feed_names.append("decrets")
            elif text_type == "arrete":
                feed_names.append("arretes")

        for feed_name in feed_names:
            texts = await self._fetch_rss_feed(feed_name)
            all_texts.extend(texts)

        # Filtrer par mots-clés
        matching_texts = []
        for text in all_texts:
            if self._matches_sector_keywords(text, keywords):
                # Ajouter les mots-clés correspondants
                text.mots_cles = [
                    kw for kw in keywords
                    if kw.lower() in f"{text.titre} {text.resume or ''}".lower()
                ]
                matching_texts.append(text)

        return matching_texts

    async def collect(self, **kwargs: Any) -> list[Regulation]:
        """Collecte les textes juridiques récents.

        Récupère les textes du JORF et filtre selon les secteurs configurés.

        Returns:
            Liste des réglementations.
        """
        sectors_config = load_sectors()
        active_sectors = [s for s in sectors_config.sectors if s.actif]

        if not active_sectors:
            self._logger.warning("Aucun secteur actif configuré")
            return []

        self.log_collection_start(f"{len(active_sectors)} secteurs")

        all_texts: list[LegalText] = []

        # Récupérer les flux RSS
        for feed_name in LEGIFRANCE_RSS_FEEDS.keys():
            texts = await self._fetch_rss_feed(feed_name)
            all_texts.extend(texts)

        # Filtrer par secteurs
        regulations = []
        seen_hashes = set()

        for text in all_texts:
            text_hash = self._generate_hash(text)
            if text_hash in seen_hashes:
                continue

            matching_sectors = []
            for sector in active_sectors:
                keywords = sector.mots_cles + sector.mots_cles_legifrance
                if self._matches_sector_keywords(text, keywords):
                    matching_sectors.append(sector.id)

            if matching_sectors:
                seen_hashes.add(text_hash)

                regulation = Regulation(
                    id=generate_uuid(),
                    type=text.type,
                    numero=text.numero,
                    titre=text.titre,
                    titre_court=text.titre_court,
                    date_signature=text.date_signature,
                    date_publication=text.date_publication,
                    source="legifrance",
                    url=text.url,
                    resume=text.resume,
                    hash_content=text_hash,
                )
                regulation.set_mots_cles(text.mots_cles)
                regulation.set_secteurs(matching_sectors)
                regulations.append(regulation)

        self.log_collection_end("Légifrance", len(regulations))
        return regulations

    async def collect_for_competitor(
        self,
        siren: str,
        **kwargs: Any,
    ) -> list[Regulation]:
        """Non applicable pour Légifrance.

        Légifrance contient des textes généraux, pas spécifiques à une entreprise.
        Utilisez collect() ou collect_for_sector() à la place.
        """
        self._logger.warning("collect_for_competitor non applicable pour Légifrance")
        return []

    async def collect_for_sector(
        self,
        sector_id: str,
        session: Optional[AsyncSession] = None,
    ) -> list[Regulation]:
        """Collecte les textes pour un secteur spécifique.

        Args:
            sector_id: Identifiant du secteur.
            session: Session SQLAlchemy (optionnel).

        Returns:
            Liste des réglementations.
        """
        sectors_config = load_sectors()
        sector = next(
            (s for s in sectors_config.sectors if s.id == sector_id),
            None
        )

        if not sector:
            self._logger.error(f"Secteur non trouvé: {sector_id}")
            return []

        self._logger.info(f"Collecte pour secteur: {sector.nom}")

        keywords = sector.mots_cles + sector.mots_cles_legifrance
        texts = await self._search_by_keywords(keywords)

        regulations = []
        for text in texts:
            regulation = Regulation(
                id=generate_uuid(),
                type=text.type,
                numero=text.numero,
                titre=text.titre,
                titre_court=text.titre_court,
                date_signature=text.date_signature,
                date_publication=text.date_publication,
                source="legifrance",
                url=text.url,
                resume=text.resume,
                hash_content=self._generate_hash(text),
            )
            regulation.set_mots_cles(text.mots_cles)
            regulation.set_secteurs([sector_id])
            regulations.append(regulation)

        return regulations

    async def collect_and_save(
        self,
        session: AsyncSession,
        sector_id: Optional[str] = None,
    ) -> CollectionResult:
        """Collecte et sauvegarde les textes juridiques.

        Args:
            session: Session SQLAlchemy.
            sector_id: Secteur spécifique (optionnel).

        Returns:
            Résultat de la collecte.
        """
        started_at = datetime.now()
        errors = []
        items_collected = 0
        items_saved = 0

        try:
            if sector_id:
                regulations = await self.collect_for_sector(sector_id)
            else:
                regulations = await self.collect()

            items_collected = len(regulations)

            for regulation in regulations:
                # Vérifier si le texte existe déjà (par hash)
                if regulation.hash_content:
                    existing = await session.execute(
                        select(Regulation).where(
                            Regulation.hash_content == regulation.hash_content
                        )
                    )
                    if existing.scalar_one_or_none():
                        continue

                session.add(regulation)
                items_saved += 1

            await session.commit()

            return CollectionResult(
                collector_name=self.name,
                target=sector_id or "all_sectors",
                success=True,
                items_collected=items_collected,
                items_saved=items_saved,
                started_at=started_at,
                finished_at=datetime.now(),
            )

        except Exception as e:
            self._logger.error(f"Erreur collecte Légifrance: {e}")
            await session.rollback()
            return CollectionResult(
                collector_name=self.name,
                target=sector_id or "all_sectors",
                success=False,
                items_collected=items_collected,
                errors=[str(e)],
                started_at=started_at,
                finished_at=datetime.now(),
            )

    async def check_deadlines(
        self,
        session: AsyncSession,
        days_ahead: int = 30,
    ) -> list[RegulationDeadline]:
        """Vérifie les échéances réglementaires à venir.

        Args:
            session: Session SQLAlchemy.
            days_ahead: Nombre de jours à regarder.

        Returns:
            Liste des échéances proches.
        """
        from datetime import timedelta

        today = date.today()
        deadline_date = today + timedelta(days=days_ahead)

        result = await session.execute(
            select(RegulationDeadline).where(
                RegulationDeadline.date_echeance <= deadline_date,
                RegulationDeadline.date_echeance >= today,
                RegulationDeadline.statut == "a_venir",
            ).order_by(RegulationDeadline.date_echeance)
        )

        deadlines = result.scalars().all()
        self._logger.info(f"{len(deadlines)} échéances dans les {days_ahead} prochains jours")

        return list(deadlines)
